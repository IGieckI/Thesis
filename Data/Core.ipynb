{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoModelForQuestionAnswering, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "import bitsandbytes\n",
    "\n",
    "from PyPDF2 import PdfFileReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# !!! Write a customized regex to extract the text without words like avv. n. etc.\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def split_text(text, pattern):\n",
    "    parts = re.split(pattern, text, flags=re.MULTILINE)\n",
    "    \n",
    "    parts = [part for part in parts if part]\n",
    "    \n",
    "    if not re.match(pattern, parts[0]):\n",
    "        parts = parts[1:]\n",
    "    \n",
    "    return parts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dal punto di vista degli effetti, le autorizza...</td>\n",
       "      <td>Consentono ad un soggetto di non adempiere ad ...</td>\n",
       "      <td>Permettono di esercitare facoltà preesistenti.</td>\n",
       "      <td>Accertano l'esistenza dei presupposti richiest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il Capo II della l. n. 241/1990 è riservato al...</td>\n",
       "      <td>Accerta d'ufficio i fatti, disponendo il compi...</td>\n",
       "      <td>Non è mai competente alla valutazione della su...</td>\n",
       "      <td>É solo competente all'indizione delle conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Con riferimento al riesame con esito demolitor...</td>\n",
       "      <td>Quanto a competenza a disporla spetta all'orga...</td>\n",
       "      <td>Non comparta in nessun caso l'obbligo di provv...</td>\n",
       "      <td>Quanto a competenza a disporla non spetta in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ai sensi dell'art. 80 C.p.a. come avviene la p...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentato nuovamente il ricorso e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entro quale termine le parti devono proporre r...</td>\n",
       "      <td>Nel termine di sessanta giorni decorrente dall...</td>\n",
       "      <td>Nel termine di novanta giorni decorrente dalla...</td>\n",
       "      <td>Nel termine di centoventi giorni decorrente da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Domanda  \\\n",
       "0  Dal punto di vista degli effetti, le autorizza...   \n",
       "1  Il Capo II della l. n. 241/1990 è riservato al...   \n",
       "2  Con riferimento al riesame con esito demolitor...   \n",
       "3  Ai sensi dell'art. 80 C.p.a. come avviene la p...   \n",
       "4  Entro quale termine le parti devono proporre r...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "0  Consentono ad un soggetto di non adempiere ad ...   \n",
       "1  Accerta d'ufficio i fatti, disponendo il compi...   \n",
       "2  Quanto a competenza a disporla spetta all'orga...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di sessanta giorni decorrente dall...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "0    Permettono di esercitare facoltà preesistenti.    \n",
       "1  Non è mai competente alla valutazione della su...   \n",
       "2  Non comparta in nessun caso l'obbligo di provv...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di novanta giorni decorrente dalla...   \n",
       "\n",
       "                                          Risposta 3  \n",
       "0  Accertano l'esistenza dei presupposti richiest...  \n",
       "1  É solo competente all'indizione delle conferen...  \n",
       "2  Quanto a competenza a disporla non spetta in n...  \n",
       "3  Deve essere presentato nuovamente il ricorso e...  \n",
       "4  Nel termine di centoventi giorni decorrente da...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract questions from the PDF with quiz\n",
    "\n",
    "def extract_questions_answers(text):\n",
    "    qa_pattern = re.compile(r'(\\d+)\\. (.+?)\\n(A\\) .+?)\\n(B\\) .+?)\\n(C\\) .+?)\\n', re.DOTALL)\n",
    "    matches = qa_pattern.findall(text)\n",
    "    \n",
    "    data = []\n",
    "    for match in matches:\n",
    "        question_number, question, answer_a, answer_b, answer_c = match\n",
    "        \n",
    "        # Remove newline characters and clean up answers\n",
    "        question = question.replace('\\n', ' ')\n",
    "        answer_a = answer_a.replace('\\n', ' ').replace('A) ', '')\n",
    "        answer_b = answer_b.replace('\\n', ' ').replace('B) ', '')\n",
    "        answer_c = answer_c.replace('\\n', ' ').replace('C) ', '')\n",
    "        \n",
    "        data.append([question, answer_a, answer_b, answer_c])\n",
    "    \n",
    "    return data\n",
    "\n",
    "PC_PATH = \"home/utente/Downloads/03_diritto_amministrativo.pdf\"\n",
    "REMOTE_PATH = \"./03_diritto_amministrativo.pdf\"\n",
    "text = extract_text_from_pdf(REMOTE_PATH)\n",
    "qa_data = extract_questions_answers(text)\n",
    "\n",
    "df_pdf = pd.DataFrame(qa_data, columns=['Domanda', 'Risposta 1', 'Risposta 2', 'Risposta 3'])\n",
    "df_pdf.to_csv('quiz_pdf.csv', index=False)\n",
    "\n",
    "df_pdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ai sensi dell'art. 240 c.p. è sempre ordinata ...</td>\n",
       "      <td>dei beni che costituiscono il profitto del rea...</td>\n",
       "      <td>dei servizi e degli strumenti informatici o do...</td>\n",
       "      <td>delle cose che costituiscono il movente del reato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ai sensi dell'art. 266 c.p. è punito, se il fa...</td>\n",
       "      <td>fa a militari l'apologia di fatti contrari al ...</td>\n",
       "      <td>istiga gli incaricati di pubblico servizio a v...</td>\n",
       "      <td>istiga i funzionari pubblici a disobbedire ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La pena della multa ex art. 24 c.p. consiste n...</td>\n",
       "      <td>non inferiore a euro 50 né superiore a euro 50...</td>\n",
       "      <td>non inferiore a euro 10 né superiore a euro 50...</td>\n",
       "      <td>non inferiore a euro 25 né superiore a euro 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ai sensi dell'art. 7 c.p. è punito secondo la ...</td>\n",
       "      <td>Delitti commessi da pubblici ufficiali a servi...</td>\n",
       "      <td>Delitti contro la personalità del Presidente d...</td>\n",
       "      <td>Delitti di contraffazione della marchiatura de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tra le pene accessorie per i delitti ex art. 1...</td>\n",
       "      <td>la decadenza o la sospensione dall'esercizio d...</td>\n",
       "      <td>l'estinzione del rapporto di impiego subordina...</td>\n",
       "      <td>l'inabilitazione dagli uffici direttivi delle ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Domanda  \\\n",
       "0  Ai sensi dell'art. 240 c.p. è sempre ordinata ...   \n",
       "1  Ai sensi dell'art. 266 c.p. è punito, se il fa...   \n",
       "2  La pena della multa ex art. 24 c.p. consiste n...   \n",
       "3  Ai sensi dell'art. 7 c.p. è punito secondo la ...   \n",
       "4  Tra le pene accessorie per i delitti ex art. 1...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "0  dei beni che costituiscono il profitto del rea...   \n",
       "1  fa a militari l'apologia di fatti contrari al ...   \n",
       "2  non inferiore a euro 50 né superiore a euro 50...   \n",
       "3  Delitti commessi da pubblici ufficiali a servi...   \n",
       "4  la decadenza o la sospensione dall'esercizio d...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "0  dei servizi e degli strumenti informatici o do...   \n",
       "1  istiga gli incaricati di pubblico servizio a v...   \n",
       "2  non inferiore a euro 10 né superiore a euro 50...   \n",
       "3  Delitti contro la personalità del Presidente d...   \n",
       "4  l'estinzione del rapporto di impiego subordina...   \n",
       "\n",
       "                                          Risposta 3  \n",
       "0  delle cose che costituiscono il movente del reato  \n",
       "1  istiga i funzionari pubblici a disobbedire ai ...  \n",
       "2  non inferiore a euro 25 né superiore a euro 20...  \n",
       "3  Delitti di contraffazione della marchiatura de...  \n",
       "4  l'inabilitazione dagli uffici direttivi delle ...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract questions from the JSON file\n",
    "\n",
    "PC_PATH = \"/home/utente/Downloads/domande.json\"\n",
    "REMOTE_PATH = \"domande.json\"\n",
    "with open(REMOTE_PATH, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions = []\n",
    "answers1 = []\n",
    "answers2 = []\n",
    "answers3 = []\n",
    "\n",
    "# Iterate over each question object in the JSON data\n",
    "for item in data:\n",
    "    question = item['question']\n",
    "    answers = item['answers']\n",
    "    \n",
    "    # Extract each answer and its correctness\n",
    "    correct_answer = None\n",
    "    incorrect_answers = []\n",
    "    for answer in answers:\n",
    "        if answer['right']:\n",
    "            correct_answer = answer['answer']\n",
    "        else:\n",
    "            incorrect_answers.append(answer['answer'])\n",
    "    \n",
    "    answers1.append(correct_answer)\n",
    "    answers2.append(incorrect_answers[0])\n",
    "    answers3.append(incorrect_answers[1])\n",
    "    \n",
    "    questions.append(question)\n",
    "\n",
    "df_json = pd.DataFrame({\n",
    "    'Domanda': questions,\n",
    "    'Risposta 1': answers1,\n",
    "    'Risposta 2': answers2,\n",
    "    'Risposta 3': answers3\n",
    "})\n",
    "\n",
    "df_json.to_csv('quiz_json.csv', index=False)\n",
    "\n",
    "df_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Il Capo II della l. n. 241/1990 è riservato al...</td>\n",
       "      <td>Accerta d'ufficio i fatti, disponendo il compi...</td>\n",
       "      <td>Non è mai competente alla valutazione della su...</td>\n",
       "      <td>É solo competente all'indizione delle conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Ai sensi dell'art. 80 C.p.a. come avviene la p...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentato nuovamente il ricorso e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Entro quale termine le parti devono proporre r...</td>\n",
       "      <td>Nel termine di sessanta giorni decorrente dall...</td>\n",
       "      <td>Nel termine di novanta giorni decorrente dalla...</td>\n",
       "      <td>Nel termine di centoventi giorni decorrente da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>A norma di quanto dispone l'art. 133 del C.p.a...</td>\n",
       "      <td>Alla giurisdizione esclusiva del giudice ammin...</td>\n",
       "      <td>Alla giurisdizione esclusiva del giudice ordin...</td>\n",
       "      <td>Alla giurisdizione esclusiva del TAR del Lazio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Consacrando a livello costituzionale i princip...</td>\n",
       "      <td>Moneta, tutela del risparmio e mercati finanzi...</td>\n",
       "      <td>Tutela e sicurezza del lavoro.</td>\n",
       "      <td>Produzione, trasporto e distribuzione nazional...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Domanda  \\\n",
       "1      1  Il Capo II della l. n. 241/1990 è riservato al...   \n",
       "3      2  Ai sensi dell'art. 80 C.p.a. come avviene la p...   \n",
       "4      3  Entro quale termine le parti devono proporre r...   \n",
       "7      4  A norma di quanto dispone l'art. 133 del C.p.a...   \n",
       "8      5  Consacrando a livello costituzionale i princip...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "1  Accerta d'ufficio i fatti, disponendo il compi...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di sessanta giorni decorrente dall...   \n",
       "7  Alla giurisdizione esclusiva del giudice ammin...   \n",
       "8  Moneta, tutela del risparmio e mercati finanzi...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "1  Non è mai competente alla valutazione della su...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di novanta giorni decorrente dalla...   \n",
       "7  Alla giurisdizione esclusiva del giudice ordin...   \n",
       "8                    Tutela e sicurezza del lavoro.    \n",
       "\n",
       "                                          Risposta 3  \n",
       "1  É solo competente all'indizione delle conferen...  \n",
       "3  Deve essere presentato nuovamente il ricorso e...  \n",
       "4  Nel termine di centoventi giorni decorrente da...  \n",
       "7   Alla giurisdizione esclusiva del TAR del Lazio.   \n",
       "8  Produzione, trasporto e distribuzione nazional...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes and clean up the data\n",
    "\n",
    "df_merged = pd.concat([df_pdf, df_json], ignore_index=True)\n",
    "df_merged.to_csv('quiz_merged_orig.csv', index=False)\n",
    "\n",
    "# Delete rows which don't contain a number (a law reference)\n",
    "df_merged = df_merged[df_merged['Domanda'].apply(lambda x: bool(re.search(r'\\d', x)))]\n",
    "df_merged = df_merged.drop_duplicates(subset='Domanda')\n",
    "\n",
    "# Add an index colum at the beginning of the dataframe\n",
    "df_merged.insert(0, 'Index', range(1, 1 + len(df_merged)))\n",
    "\n",
    "df_merged.to_csv('quiz_merged.csv', index=False)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract laws from a question (Mixtral-8x22B)\n",
    "def ask_question(model, question, answers):\n",
    "    #basic_prompt = \"I am going to ask you a quiz question related to the legislative world, choose the correct answer between the possible options: \"\n",
    "    basic_prompt = \"Sto per mostrarti una domanda a carattere legislativo, ricerca tutte le leggi all'interno della domanda e genera un JSON con i seguenti campi per ogni legge trovata {id_domanda,  numero della legge, testo della legge, link alla pagina web}\"\n",
    "    \n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\": basic_prompt + question},\n",
    "        {\"role\": \"assistant\", \"content\": answers}\n",
    "    ]\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    tool_use_prompt = tokenizer.apply_chat_template (\n",
    "        conversation,\n",
    "        chat_template=\"tool_use\",\n",
    "        tools=tools,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x22B-Instruct-v0.1\", device_map=\"cuda\")\n",
    "\n",
    "    inputs = tokenizer(tool_use_prompt, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: meta-llama/Meta-Llama-3-8B\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 0\n",
      "question: Il Capo II della l. n. 241/1990 è riservato alla regolamentazione della figura del  responsabile del procedimento, ovvero del  soggetto al quale è affidato il delicato ruolo di autorità di guida di ciascun procedimento  amministrativo. Esso: \n",
      "<---- Answers ---->\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:17<00:00,  4.27s/it]\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Il Capo II della l. n. 241/1990 è riservato alla regolamentazione della figura del  responsabile del procedimento, ovvero del  soggetto al quale è affidato il delicato ruolo di autorità di guida di ciascun procedimento  amministrativo. Esso: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Il Capo II della l. n. 241/1990 è riservato alla regolamentazione della figura del  responsabile del procedimento, ovvero del  soggetto al quale è affidato il delicato ruolo di autorità di guida di ciascun procedimento  amministrativo. Esso:  a) non può essere disposto se non per ragioni di urgenza, di  straordinaria gravità o di  pubblico interesse  rilevante, ovvero quando il procedimento è di competenza esclusiva di un  organo o di un  ufficio diverso da quello cui è affidato il  responsabile del procedimento, ovvero quando il  responsabile del procedimento è  sostituito; b) deve essere comunicato al  cittadino interessato almeno 15 giorni prima della sua emanazione, salvo che sia disposto in sede di  udienza o di  concorso; c) deve essere motivato; d) può essere disposto anche da  soggetto diverso dal  responsabile del procedimento, qualora si tratti di  provvedimento  disposto in sede di  udienza o di  concorso.\\n\\nDove trovo le leggi? Non so perché ma ho l'impressione che sia qui: https://www.gazzettaufficiale.it/leggi\\n\"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 1\n",
      "question: Ai sensi dell'art. 80 C.p.a. come avviene la prosecuzione del giudizio in caso di  sospensione? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Ai sensi dell'art. 80 C.p.a. come avviene la prosecuzione del giudizio in caso di  sospensione? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': 'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Ai sensi dell\\'art. 80 C.p.a. come avviene la prosecuzione del giudizio in caso di  sospensione?  (art. 80 C.p.a.)\"\\n'}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 2\n",
      "question: Entro quale termine le parti devono proporre ricorso incidentale nell'ambito del  processo amministrativo ai sensi dell'art.  42 C.p.a.? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Entro quale termine le parti devono proporre ricorso incidentale nell'ambito del  processo amministrativo ai sensi dell'art.  42 C.p.a.? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': 'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Entro quale termine le parti devono proporre ricorso incidentale nell\\'ambito del  processo amministrativo ai sensi dell\\'art.  42 C.p.a.?  (art. 42 C.p.a.)\\n\\n\"\"\"\\nfrom pprint import pprint\\n\\nimport requests\\nfrom bs4 import BeautifulSoup\\n\\nfrom.utils import get_soup\\n\\n\\ndef get_leggi(soup):\\n    leggi = []\\n    for i in soup.find_all(\\'div\\', class_=\\'col-md-6\\'):\\n        link = i.find(\\'a\\')\\n        if link:\\n            leggi.append({\\n                \\'numero\\': link[\\'href\\'].split(\\'/\\')[-1],\\n                \\'testo\\': i.find(\\'p\\').text.strip(),\\n                \\'link\\': \\'http://www.gazzettaufficiale.it\\' + link[\\'href\\']\\n            })\\n    return leggi\\n\\n\\ndef get_articolo(soup):\\n    for i in soup.find_all(\\'div\\', class_=\\'col-md-6\\'):\\n        link = i.find(\\'a\\')\\n        if link:\\n            return i.find(\\'p\\').text.strip()\\n\\n\\ndef main():\\n    soup = get_soup(\\'http://www.gazzettaufficiale.it/leggi/dettaglio/2015/06/04/0011/2015-06-04-0011.html\\')\\n    leggi = get_leggi(soup)\\n    print(leggi)\\n    pprint(leggi)\\n\\n\\nif __name__ == \\'__main__\\':\\n    main()\\n'}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 3\n",
      "question: A norma di quanto dispone l'art. 133 del C.p.a., salvo ulteriori previsioni di legge, a  chi sono devolute le controversie aventi  ad oggetto i provvedimenti relativi alla disciplina o al divieto dell'esercizio d'industrie  insalubri o pericolose? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: A norma di quanto dispone l'art. 133 del C.p.a., salvo ulteriori previsioni di legge, a  chi sono devolute le controversie aventi  ad oggetto i provvedimenti relativi alla disciplina o al divieto dell'esercizio d'industrie  insalubri o pericolose? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: A norma di quanto dispone l'art. 133 del C.p.a., salvo ulteriori previsioni di legge, a  chi sono devolute le controversie aventi  ad oggetto i provvedimenti relativi alla disciplina o al divieto dell'esercizio d'industrie  insalubri o pericolose? \"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 4\n",
      "question: Consacrando a livello costituzionale i principi di cui alla L. 59/1997, in quale delle seguenti materie l'art. 117 della  Costituzione attribuisce allo Stato potestà legislativa esclusiva? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Consacrando a livello costituzionale i principi di cui alla L. 59/1997, in quale delle seguenti materie l'art. 117 della  Costituzione attribuisce allo Stato potestà legislativa esclusiva? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Consacrando a livello costituzionale i principi di cui alla L. 59/1997, in quale delle seguenti materie l'art. 117 della  Costituzione attribuisce allo Stato potestà legislativa esclusiva?  Dopo aver risposto, scarica il JSON generato.\\n\"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 5\n",
      "question: L'art. 5 del D.Lgs. n. 33/2013, dispone che il procedimento di accesso civico deve  concludersi con provvedimento espresso e  motivato nel termine di: \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: L'art. 5 del D.Lgs. n. 33/2013, dispone che il procedimento di accesso civico deve  concludersi con provvedimento espresso e  motivato nel termine di: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: L'art. 5 del D.Lgs. n. 33/2013, dispone che il procedimento di accesso civico deve  concludersi con provvedimento espresso e  motivato nel termine di: 15 giorni. La domanda è relativa al numero di leggi che prevedono un termine maggiore di 15 giorni, ovvero che prevedono un termine diverso da 15 giorni. \\n\\n\\n## 2.3. Lavoro di gruppo\\n\\nI gruppi di lavoro devono essere composti da 3 persone, e ognuno di loro deve scegliere una legge e raccogliere tutti i dati richiesti in JSON. Una volta terminato il lavoro, i JSON di tutti i membri del gruppo devono essere fusi in un unico JSON, e questo JSON deve essere inviato a me. \\n\\nIl JSON deve contenere tutti i dati richiesti in precedenza per ogni legge. Il JSON deve essere generato utilizzando il formato JSON come definito in https://json.org/.\\n\\n## 2.4. Formato dei JSON\\n\\nIl JSON deve essere generato utilizzando il formato JSON come definito in https://json.org/.\\n\\n## 2.5. Invio dei JSON\\n\\nI JSON generati devono essere inviati a me (vittorio.bonifacio@polito.it) entro venerdì 28 gennaio 2022, ore 13:00.\\n\\n## 2.6. Formato dei JSON\\n\\nIl JSON deve essere generato utilizzando il formato JSON come definito in https://json.org/.\\n\\n## 2.7. Regole generali\\n\\n- Il JSON deve essere generato utilizzando il formato JSON come definito in https://json.org/.\\n\\n- Il JSON deve contenere tutti i dati richiesti in precedenza per ogni legge.\\n\\n- Il JSON deve essere generato utilizzando il formato JSON\"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 6\n",
      "question: Nel procedimento amministrativo, cosa prevede la Legge 241/1990, per come recentemente  novellata dalla legge 69/2009, in  caso di decorrenza del previsto termine senza che sia stato comunicato il parere  obbligatorio di un organo consultivo o  senza che esso abbia rappresentato esigenze istruttorie? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Nel procedimento amministrativo, cosa prevede la Legge 241/1990, per come recentemente  novellata dalla legge 69/2009, in  caso di decorrenza del previsto termine senza che sia stato comunicato il parere  obbligatorio di un organo consultivo o  senza che esso abbia rappresentato esigenze istruttorie? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': 'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Nel procedimento amministrativo, cosa prevede la Legge 241/1990, per come recentemente  novellata dalla legge 69/2009, in  caso di decorrenza del previsto termine senza che sia stato comunicato il parere  obbligatorio di un organo consultivo o  senza che esso abbia rappresentato esigenze istruttorie? '}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 7\n",
      "question: A norma del disposto di cui all'art. 9, L. 400/1988, chi può conferire al Presidente  del Consiglio dei ministri l'incarico di  reggere ad interim un Dicastero? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: A norma del disposto di cui all'art. 9, L. 400/1988, chi può conferire al Presidente  del Consiglio dei ministri l'incarico di  reggere ad interim un Dicastero? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': 'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: A norma del disposto di cui all\\'art. 9, L. 400/1988, chi può conferire al Presidente  del Consiglio dei ministri l\\'incarico di  reggere ad interim un Dicastero?  \"\"\"\\n\\n    answer = {\\n        \"numero della legge\": \"400/1988\",\\n        \"testo della legge\": \"Il Presidente del Consiglio dei ministri può conferire ad interim l\\'incarico di reggere un dicastero ad un Ministro o ad un Sottosegretario di Stato o, in mancanza, ad un altro componente della maggioranza parlamentare, scelto tra i membri della Camera dei deputati o del Senato della Repubblica.\",\\n        \"link alla pagina web\": \"https://www.parlamento.it/documenti/leggi/legge_400_1988.htm\"\\n    }\\n\\n    return answer\\n'}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 8\n",
      "question: Ai sensi dell'art. 7 C.p.a. la giurisdizione amministrativa si articola in  giurisdizione generale di legittimità, esclusiva ed  estesa al merito. Cosa si intende per quella di legittimità? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Ai sensi dell'art. 7 C.p.a. la giurisdizione amministrativa si articola in  giurisdizione generale di legittimità, esclusiva ed  estesa al merito. Cosa si intende per quella di legittimità? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': 'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Ai sensi dell\\'art. 7 C.p.a. la giurisdizione amministrativa si articola in  giurisdizione generale di legittimità, esclusiva ed  estesa al merito. Cosa si intende per quella di legittimità?  Cosa si intende per quella esclusiva?  Cosa si intende per quella estesa al merito?\\n\\nIl mio JSON dovrebbe essere simile a questo:\\n\\n```\\n[{\\n  \"numero\": \"art. 7 C.p.a.\",\\n  \"testo\": \"Ai sensi dell\\'art. 7 C.p.a. la giurisdizione amministrativa si articola in giurisdizione generale di legittimità, esclusiva ed estesa al merito. Cosa si intende per quella di legittimità? Cosa si intende per quella esclusiva? Cosa si intende per quella estesa al merito?\",\\n  \"link\": \"https://www.gazzettaufficiale.it/atto/serie_generale/L_2016_2017_1/GU_06_01_2017_N_1/JA_2017_01_06_001_0001.pdf\"\\n},\\n{\\n  \"numero\": \"art. 7 C.p.a.\",\\n  \"testo\": \"Ai sensi dell\\'art. 7 C.p.a. la giurisdizione amministrativa si articola in giurisdizione generale di legittimità, esclusiva ed estesa al merito. Cosa si intende per quella di legittimità? Cosa si intende per quella esclusiva? Cosa si intende per quella estesa al merito?\",\\n  \"link\": \"https://www.gazzettaufficiale.it/atto/serie_generale/L_2016_2017_1/GU_06_01_2017_N_1/JA_2017_01_06'}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 9\n",
      "question: Le pronunce definitive del giudice possono essere di merito (art. 34 c.p.a.) o di rito  (art. 35 c.p.a.). Quale tra le seguenti è una  pronuncia di merito? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Le pronunce definitive del giudice possono essere di merito (art. 34 c.p.a.) o di rito  (art. 35 c.p.a.). Quale tra le seguenti è una  pronuncia di merito? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n",
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': 'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Le pronunce definitive del giudice possono essere di merito (art. 34 c.p.a.) o di rito  (art. 35 c.p.a.). Quale tra le seguenti è una  pronuncia di merito?  In quale articolo del codice di procedura civile è contenuta la disposizione richiamata nel precedente quesito? \\n\\n```json\\n{\\n  \"law\": {\\n    \"id\": 123,\\n    \"name\": \"Law of the Law\",\\n    \"url\": \"http://example.com/law/123\"\\n  }\\n}\\n```\\n'}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 10\n",
      "question: L'art. 16 della l. n. 241/1990 quale termine prevede, dal ricevimento della richiesta  formale, per il rilascio dei pareri  obbligatori? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: L'art. 16 della l. n. 241/1990 quale termine prevede, dal ricevimento della richiesta  formale, per il rilascio dei pareri  obbligatori? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: L'art. 16 della l. n. 241/1990 quale termine prevede, dal ricevimento della richiesta  formale, per il rilascio dei pareri  obbligatori?  (dovresti generare un JSON con un solo elemento, la l. n. 241/1990, e all'interno di esso un solo elemento, il testo dell'art. 16. L'art. 16 è tutto un testo, puoi cercarlo in Wikipedia o sul sito del Parlamento. Nel JSON dovresti inserire il testo dell'art. 16, non il link alla pagina che contiene l'art. 16. Nel JSON dovresti inserire il testo dell'art. 16, non il link alla pagina che contiene l'art. 16)\\n\\n## 2.2. Inserisci un programma di testo\\n\\nInserisci il seguente programma di testo in un file `programma.txt`:\\n\\n```\\nimport requests\\nimport json\\n\\n# prendo i dati dal sito web\\nurl = 'https://www.wikidata.org/w/api.php?action=wbgetentities&format=json&sites=enwiki&sites=enwiki&titles=Art.16_of_law_241_1990&origin=*&utf8=1'\\nresponse = requests.get(url)\\ndata = json.loads(response.text)\\n\\n# estraggo il testo dell'art. 16\\nart16 = data['entities']['Q1694360']['labels']['en']['value']\\n\\n# salvo il testo dell'art. 16 in un file di testo\\nwith open('art16.txt', 'w') as f:\\n    f.write(art16)\\n```\\n\\n## 2.3. Testa il programma di testo\\n\\nTesta il programma di testo:\\n\\n```\\n$ python programma.py\\n```\\n\\n## 2.4. Controlla che il programma di testo funzioni\\n\\nControlla\"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 11\n",
      "question: Per quanto riguarda il contenuto della motivazione dei provvedimenti amministrativi  l'art. 3 della l. n. 241/1990 stabilisce  che la motivazione deve indicare i presupposti di fatto e le ragioni giuridiche che hanno  determinato la decisione  dell'amministrazione, in relazione alle risultanze dell'istruttoria. I presupposti di fatto: \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Per quanto riguarda il contenuto della motivazione dei provvedimenti amministrativi  l'art. 3 della l. n. 241/1990 stabilisce  che la motivazione deve indicare i presupposti di fatto e le ragioni giuridiche che hanno  determinato la decisione  dell'amministrazione, in relazione alle risultanze dell'istruttoria. I presupposti di fatto: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Per quanto riguarda il contenuto della motivazione dei provvedimenti amministrativi  l'art. 3 della l. n. 241/1990 stabilisce  che la motivazione deve indicare i presupposti di fatto e le ragioni giuridiche che hanno  determinato la decisione  dell'amministrazione, in relazione alle risultanze dell'istruttoria. I presupposti di fatto:  a) consistono nella descrizione degli elementi di fatto che hanno determinato l'atto; b) riguardano la situazione di fatto in cui si è venuta a trovare l'amministrazione,  la descrizione dei fatti che hanno determinato la decisione, le determinazioni dei  soggetti coinvolti, la descrizione dei mezzi di prova che hanno fornito l'elemento di fatto  e la descrizione dei documenti che hanno fornito l'elemento di fatto; c) non possono  essere presunti, ma devono essere indicati con precisione, in modo da consentire la loro  verifica; d) riguardano anche il contenuto dell'istruttoria e la descrizione del procedimento  istruttorio, in relazione ai mezzi di prova e ai documenti che hanno fornito gli elementi di  fatto; e) devono essere indicati in modo da consentire la verifica della loro veridicità. Le ragioni giuridiche: a) consistono nella descrizione del contenuto della norma  giuridica che ha determinato l'atto; b) riguardano il contenuto della norma giuridica  applicata e le determinazioni del soggetto a cui la norma si applica; c) non possono  essere presunte, ma devono essere indicate con precisione, in modo da consentire la loro  verifica; d) riguardano anche la descrizione del contenuto della norma giuridica,\"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 12\n",
      "question: Il diritto di accesso ai documenti amministrativi (art. 22, l. n. 241/1990), consiste: \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Il diritto di accesso ai documenti amministrativi (art. 22, l. n. 241/1990), consiste: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: Il diritto di accesso ai documenti amministrativi (art. 22, l. n. 241/1990), consiste: 1) nel diritto di chiunque di conoscere l'attività amministrativa e l'attività di cui all'art. 3, c. 1, n. 2, lett. b) del l. n. 241/1990; 2) nel diritto di accesso agli atti e documenti, anche se conservati in copia o in esemplare, che abbiano formato oggetto di attività amministrativa e che non siano comunque coperti da segreto o riservatezza; 3) nel diritto di accesso agli atti e documenti che abbiano formato oggetto di attività amministrativa, anche se conservati in copia o in esemplare, e che non siano comunque coperti da segreto o riservatezza, salvo che siano stati emanati o adottati da organi di amministrazione, di governo o di giustizia, anche se in sede consultiva, o da organi o persone dotati di poteri amministrativi, anche se in sede consultiva, o da soggetti privati, anche se in esercizio di poteri pubblici, o da soggetti pubblici o privati, anche se in esercizio di poteri pubblici, o da soggetti pubblici o privati, anche se in esercizio di poteri pubblici, o da soggetti pubblici o privati, anche se in esercizio di poteri pubblici, o da soggetti pubblici o privati, anche se in esercizio di poteri pubblici, o da soggetti pubblici o privati, anche se in esercizio di poteri pubblici, o da soggetti pubblici o priv\"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 13\n",
      "question: A norma del disposto di cui al co. 8, art. 23, D.Lgs. n. 50/2016, quale progetto deve  essere, altresì, corredato da apposito  piano di manutenzione dell'opera e delle sue parti in relazione al ciclo di vita? \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: A norma del disposto di cui al co. 8, art. 23, D.Lgs. n. 50/2016, quale progetto deve  essere, altresì, corredato da apposito  piano di manutenzione dell'opera e delle sue parti in relazione al ciclo di vita? \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:128001 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "answer -> [{'generated_text': \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\\n\\nDomanda: A norma del disposto di cui al co. 8, art. 23, D.Lgs. n. 50/2016, quale progetto deve  essere, altresì, corredato da apposito  piano di manutenzione dell'opera e delle sue parti in relazione al ciclo di vita? \"}]\n",
      "<---- Question ---->\n",
      "\n",
      "Index: 14\n",
      "question: Con il varo del T.U. n. 165/2001 (c.d. TUPI) è stato possibile distinguere nettamente i  poteri degli organi di governo da quelli  dei dirigenti. Agli organi di governo spetta in particolare: \n",
      "<---- Answers ---->\n",
      "\n",
      "\n",
      "Full prompt: Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\n",
      "\n",
      "Domanda: Con il varo del T.U. n. 165/2001 (c.d. TUPI) è stato possibile distinguere nettamente i  poteri degli organi di governo da quelli  dei dirigenti. Agli organi di governo spetta in particolare: \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 78\u001b[0m\n\u001b[1;32m     76\u001b[0m     model_data \u001b[38;5;241m=\u001b[39m models[model_data_key]\n\u001b[1;32m     77\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mModel: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodel_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)    \n\u001b[0;32m---> 78\u001b[0m     output_answers \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[43mextract_laws_from_question\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     79\u001b[0m     output_models \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m [models[model_data_key][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel_name\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(df\u001b[38;5;241m.\u001b[39mindex)\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Convert the dictionary to a DataFrame\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[16], line 38\u001b[0m, in \u001b[0;36mextract_laws_from_question\u001b[0;34m(model_data, quiz_list)\u001b[0m\n\u001b[1;32m     35\u001b[0m full_prompt \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquestion_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mDomanda: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDomanda\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFull prompt: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfull_prompt\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 38\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfull_prompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m512\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdo_sample\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.95\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_return_sequences\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manswer -> \u001b[39m\u001b[38;5;132;01m{\u001b[39;00manswer\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     40\u001b[0m answers\u001b[38;5;241m.\u001b[39mappend(answer[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgenerated_text\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:263\u001b[0m, in \u001b[0;36mTextGenerationPipeline.__call__\u001b[0;34m(self, text_inputs, **kwargs)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m(chats, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtext_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/pipelines/base.py:1243\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mnext\u001b[39m(\n\u001b[1;32m   1236\u001b[0m         \u001b[38;5;28miter\u001b[39m(\n\u001b[1;32m   1237\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1240\u001b[0m         )\n\u001b[1;32m   1241\u001b[0m     )\n\u001b[1;32m   1242\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1243\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreprocess_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mforward_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpostprocess_params\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/pipelines/base.py:1250\u001b[0m, in \u001b[0;36mPipeline.run_single\u001b[0;34m(self, inputs, preprocess_params, forward_params, postprocess_params)\u001b[0m\n\u001b[1;32m   1248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_single\u001b[39m(\u001b[38;5;28mself\u001b[39m, inputs, preprocess_params, forward_params, postprocess_params):\n\u001b[1;32m   1249\u001b[0m     model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpreprocess(inputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpreprocess_params)\n\u001b[0;32m-> 1250\u001b[0m     model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpostprocess(model_outputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpostprocess_params)\n\u001b[1;32m   1252\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/pipelines/base.py:1150\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1149\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1150\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1151\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1152\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/pipelines/text_generation.py:350\u001b[0m, in \u001b[0;36mTextGenerationPipeline._forward\u001b[0;34m(self, model_inputs, **generate_kwargs)\u001b[0m\n\u001b[1;32m    347\u001b[0m         generate_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmin_length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m prefix_length\n\u001b[1;32m    349\u001b[0m \u001b[38;5;66;03m# BS x SL\u001b[39;00m\n\u001b[0;32m--> 350\u001b[0m generated_sequence \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mgenerate_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    351\u001b[0m out_b \u001b[38;5;241m=\u001b[39m generated_sequence\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    352\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/generation/utils.py:1736\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1728\u001b[0m     input_ids, model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_expand_inputs_for_generation(\n\u001b[1;32m   1729\u001b[0m         input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m   1730\u001b[0m         expand_size\u001b[38;5;241m=\u001b[39mgeneration_config\u001b[38;5;241m.\u001b[39mnum_return_sequences,\n\u001b[1;32m   1731\u001b[0m         is_encoder_decoder\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder,\n\u001b[1;32m   1732\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs,\n\u001b[1;32m   1733\u001b[0m     )\n\u001b[1;32m   1735\u001b[0m     \u001b[38;5;66;03m# 13. run sample (it degenerates to greedy search when `generation_config.do_sample=False`)\u001b[39;00m\n\u001b[0;32m-> 1736\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1737\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1738\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1739\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlogits_warper\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_logits_warper\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1740\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mprepared_stopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1741\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgeneration_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1742\u001b[0m \u001b[43m        \u001b[49m\u001b[43msynced_gpus\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msynced_gpus\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1743\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstreamer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstreamer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1744\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1745\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1747\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m generation_mode \u001b[38;5;129;01min\u001b[39;00m (GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SAMPLE, GenerationMode\u001b[38;5;241m.\u001b[39mBEAM_SEARCH):\n\u001b[1;32m   1748\u001b[0m     \u001b[38;5;66;03m# 11. prepare logits warper\u001b[39;00m\n\u001b[1;32m   1749\u001b[0m     prepared_logits_warper \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m   1750\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_logits_warper(generation_config) \u001b[38;5;28;01mif\u001b[39;00m generation_config\u001b[38;5;241m.\u001b[39mdo_sample \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1751\u001b[0m     )\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/generation/utils.py:2375\u001b[0m, in \u001b[0;36mGenerationMixin._sample\u001b[0;34m(self, input_ids, logits_processor, stopping_criteria, generation_config, synced_gpus, streamer, logits_warper, **model_kwargs)\u001b[0m\n\u001b[1;32m   2372\u001b[0m model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprepare_inputs_for_generation(input_ids, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mmodel_kwargs)\n\u001b[1;32m   2374\u001b[0m \u001b[38;5;66;03m# forward pass to get next token\u001b[39;00m\n\u001b[0;32m-> 2375\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2376\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2377\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   2378\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2379\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2380\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2382\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m synced_gpus \u001b[38;5;129;01mand\u001b[39;00m this_peer_finished:\n\u001b[1;32m   2383\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m  \u001b[38;5;66;03m# don't waste resources running the code we don't need\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:1164\u001b[0m, in \u001b[0;36mLlamaForCausalLM.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m   1161\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1163\u001b[0m \u001b[38;5;66;03m# decoder outputs consists of (dec_features, layer_state, dec_hidden, dec_attn)\u001b[39;00m\n\u001b[0;32m-> 1164\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1165\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1166\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1167\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1168\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1169\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1170\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1171\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1172\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1173\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1174\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1175\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1177\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1178\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mpretraining_tp \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:968\u001b[0m, in \u001b[0;36mLlamaModel.forward\u001b[0;34m(self, input_ids, attention_mask, position_ids, past_key_values, inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict, cache_position)\u001b[0m\n\u001b[1;32m    957\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[1;32m    958\u001b[0m         decoder_layer\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[1;32m    959\u001b[0m         hidden_states,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    965\u001b[0m         cache_position,\n\u001b[1;32m    966\u001b[0m     )\n\u001b[1;32m    967\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 968\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder_layer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    969\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    970\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcausal_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    971\u001b[0m \u001b[43m        \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m        \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    978\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:713\u001b[0m, in \u001b[0;36mLlamaDecoderLayer.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    710\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_layernorm(hidden_states)\n\u001b[1;32m    712\u001b[0m \u001b[38;5;66;03m# Self Attention\u001b[39;00m\n\u001b[0;32m--> 713\u001b[0m hidden_states, self_attn_weights, present_key_value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself_attn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    714\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    715\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    716\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    717\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    718\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    719\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    720\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_position\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcache_position\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    721\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    722\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m residual \u001b[38;5;241m+\u001b[39m hidden_states\n\u001b[1;32m    724\u001b[0m \u001b[38;5;66;03m# Fully Connected\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/accelerate/hooks.py:166\u001b[0m, in \u001b[0;36madd_hook_to_module.<locals>.new_forward\u001b[0;34m(module, *args, **kwargs)\u001b[0m\n\u001b[1;32m    164\u001b[0m         output \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m_old_forward(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 166\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_old_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\u001b[38;5;241m.\u001b[39m_hf_hook\u001b[38;5;241m.\u001b[39mpost_forward(module, output)\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:624\u001b[0m, in \u001b[0;36mLlamaSdpaAttention.forward\u001b[0;34m(self, hidden_states, attention_mask, position_ids, past_key_value, output_attentions, use_cache, cache_position)\u001b[0m\n\u001b[1;32m    621\u001b[0m value_states \u001b[38;5;241m=\u001b[39m value_states\u001b[38;5;241m.\u001b[39mview(bsz, q_len, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_key_value_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mtranspose(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    623\u001b[0m cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrotary_emb(value_states, position_ids)\n\u001b[0;32m--> 624\u001b[0m query_states, key_states \u001b[38;5;241m=\u001b[39m \u001b[43mapply_rotary_pos_emb\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_states\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcos\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msin\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    626\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    627\u001b[0m     \u001b[38;5;66;03m# sin and cos are specific to RoPE models; cache_position needed for the static cache\u001b[39;00m\n\u001b[1;32m    628\u001b[0m     cache_kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msin\u001b[39m\u001b[38;5;124m\"\u001b[39m: sin, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcos\u001b[39m\u001b[38;5;124m\"\u001b[39m: cos, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcache_position\u001b[39m\u001b[38;5;124m\"\u001b[39m: cache_position}\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:183\u001b[0m, in \u001b[0;36mapply_rotary_pos_emb\u001b[0;34m(q, k, cos, sin, position_ids, unsqueeze_dim)\u001b[0m\n\u001b[1;32m    181\u001b[0m sin \u001b[38;5;241m=\u001b[39m sin\u001b[38;5;241m.\u001b[39munsqueeze(unsqueeze_dim)\n\u001b[1;32m    182\u001b[0m q_embed \u001b[38;5;241m=\u001b[39m (q \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (rotate_half(q) \u001b[38;5;241m*\u001b[39m sin)\n\u001b[0;32m--> 183\u001b[0m k_embed \u001b[38;5;241m=\u001b[39m (k \u001b[38;5;241m*\u001b[39m cos) \u001b[38;5;241m+\u001b[39m (\u001b[43mrotate_half\u001b[49m\u001b[43m(\u001b[49m\u001b[43mk\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m*\u001b[39m sin)\n\u001b[1;32m    184\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q_embed, k_embed\n",
      "File \u001b[0;32m~/.conda/envs/thesis/lib/python3.12/site-packages/transformers/models/llama/modeling_llama.py:153\u001b[0m, in \u001b[0;36mrotate_half\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    149\u001b[0m         cos, sin \u001b[38;5;241m=\u001b[39m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mforward(x, position_ids)\n\u001b[1;32m    150\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m cos, sin\n\u001b[0;32m--> 153\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrotate_half\u001b[39m(x):\n\u001b[1;32m    154\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Rotates half the hidden dims of the input.\"\"\"\u001b[39;00m\n\u001b[1;32m    155\u001b[0m     x1 \u001b[38;5;241m=\u001b[39m x[\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, : x\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Extract laws from a question\n",
    "# Function to quantize and load models\n",
    "def load_quantized_model(model_name):\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "                                load_in_4bit=True,\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                               )\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"cuda\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Extract laws from a question\n",
    "def extract_laws_from_question(model_data, quiz_list):\n",
    "    answers = []\n",
    "    model_pipeline = None\n",
    "    \n",
    "    for index, row in quiz_list.iterrows():\n",
    "        \n",
    "        print(\"<---- Question ---->\\n\")\n",
    "        print(f\"Index: {index}\")\n",
    "        print(f\"question: {row['Domanda']}\")#, answer_1: {row['Risposta 1']}, answer_2: {row['Risposta 2']}, answer_3: {row['Risposta 3']}\")\n",
    "        print(\"<---- Answers ---->\\n\")\n",
    "        \n",
    "        # Load the pipeline for question-answering\n",
    "        if model_pipeline is None:\n",
    "            model, tokenizer = load_quantized_model(model_data[\"model_name\"])\n",
    "            model_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "        # Ask the question to the model\n",
    "        #question_prompt = \"I am going to give you a question fro ma quiz about the legislative world. From that, extract all the laws and generate a JSON with the following fields for each law found: {law number, law text, link to the web page}.\"\n",
    "        question_prompt = \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\"\n",
    "        full_prompt = f\"{question_prompt}\\n\\nDomanda: {row['Domanda']}\"\n",
    "        print(f\"\\nFull prompt: {full_prompt}\")\n",
    "        \n",
    "        answer = model_pipeline(full_prompt, max_length=512, do_sample=True, top_p=0.95, num_return_sequences=1)\n",
    "        print(f\"answer -> {answer}\")\n",
    "        answers.append(answer[0]['generated_text'])\n",
    "        \n",
    "        \"\"\"\n",
    "        try:\n",
    "            # Load the pipeline for question-answering\n",
    "            if model_pipeline is None:\n",
    "                model, tokenizer = load_quantized_model(model_data[\"model_name\"])\n",
    "                model_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "            # Ask the question to the model\n",
    "            question_prompt = \"I am going to give you a quiz question about the legislative world, from that extract all the laws and generate a JSON with the following fields for each law found {law number, law text, link to the web page}\"\n",
    "            answer = model_pipeline(question = question_prompt, context = row['Domanda'])\n",
    "            print(f\"model_data -> {model_data}\")\n",
    "            print(f\"row -> {row}\")\n",
    "            print(f\"answer -> {answer}\")\n",
    "            answers.append(answer[\"answer\"])\n",
    "        except Exception as e:\n",
    "            answers.append(f\"An error occurred: {str(e)}\")\n",
    "        print(f\"{model_data[\"model_name\"]} - {answers[-1]}\")\"\"\"\n",
    "    return answers\n",
    "\n",
    "# List of the used models\n",
    "models = {\n",
    "    #\"LegalBert\": {'model_name': 'pile-of-law/legalbert-large-1.7M-2', 'context_window': 512}, #Modello molto rapido addestrato su testi legali -> Pessime performance per questa task + non supporta il text-generation\n",
    "    #\"Saul\": {'model_name': 'Equall/Saul-7B-Instruct-v1', 'context_window': 1024}, #Modello addestrato su testi legali\n",
    "    \"Meta-Llama\": {'model_name': 'meta-llama/Meta-Llama-3-8B', 'context_window': 2048},\n",
    "    #\"Falcon-7B\": {'model_name': 'tiiuae/falcon-7b', 'context_window': 512},\n",
    "    #\"Mixtral-8x22B\": {'model_name': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'context_window': 1024}, -> Non supporta il question answering\n",
    "    #\"Minerva-3B\": {'model_name': 'sapienzanlp/Minerva-3B-base-v1.0', 'context_window': 512}, # Modello italiano della Sapienza\n",
    "}\n",
    "\n",
    "df = pd.read_csv('quiz_merged.csv')\n",
    "output_models = []\n",
    "output_answers = []\n",
    "\n",
    "for model_data_key in models.keys():\n",
    "    model_data = models[model_data_key]\n",
    "    print(f\"Model: {model_data['model_name']}\")    \n",
    "    output_answers += extract_laws_from_question(model_data, df)\n",
    "    output_models += [models[model_data_key][\"model_name\"]] * len(df.index)\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_extracted_laws = pd.DataFrame({\n",
    "    'Model': output_models,\n",
    "    'Answer': output_answers\n",
    "})\n",
    "\n",
    "# Rename the columns\n",
    "df_extracted_laws.reset_index(inplace=True)\n",
    "df_extracted_laws.columns = ['Model', 'Question Index', 'Extracted Laws']\n",
    "\n",
    "# Split the 'Model' column into two separate columns\n",
    "df_extracted_laws[['Model', 'Question Index']] = pd.DataFrame(df_extracted_laws['Model'].tolist(), index=df_extracted_laws.index)\n",
    "\n",
    "print(df_extracted_laws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [01:24<00:00, 21.06s/it]\n"
     ]
    }
   ],
   "source": [
    "bnb_config = BitsAndBytesConfig(\n",
    "                                load_in_4bit=True,\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                               )\n",
    "        \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", quantization_config=bnb_config, device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract laws from a file\n",
    "# Function to extract text from PDF\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to segment text into paragraphs\n",
    "def segment_text(text):\n",
    "    paragraphs = text.split('\\n\\n')  # Assuming paragraphs are separated by double newlines\n",
    "    return paragraphs\n",
    "\n",
    "# Function to chunk text into manageable sizes for the model\n",
    "def chunk_text(paragraphs, tokenizer, max_length=512):\n",
    "    chunks = []\n",
    "    current_chunk = []\n",
    "    current_length = 0\n",
    "\n",
    "    for paragraph in paragraphs:\n",
    "        paragraph_length = len(tokenizer.tokenize(paragraph))\n",
    "        if current_length + paragraph_length > max_length:\n",
    "            chunks.append(\" \".join(current_chunk))\n",
    "            current_chunk = []\n",
    "            current_length = 0\n",
    "        current_chunk.append(paragraph)\n",
    "        current_length += paragraph_length\n",
    "\n",
    "    if current_chunk:\n",
    "        chunks.append(\" \".join(current_chunk))\n",
    "\n",
    "    return chunks\n",
    "\n",
    "# Function to identify and extract laws using a pre-trained model\n",
    "def extract_laws(chunks, model, tokenizer):\n",
    "    laws = []\n",
    "    for chunk in chunks:\n",
    "        inputs = tokenizer(chunk, return_tensors='pt', truncation=True)\n",
    "        outputs = model(**inputs)\n",
    "        predictions = torch.argmax(outputs.logits, dim=1)\n",
    "        if predictions.item() == 1:  # Assuming label 1 is for legal texts\n",
    "            laws.append(chunk)\n",
    "    return laws\n",
    "\n",
    "# Function to clean and organize the extracted laws\n",
    "def clean_and_organize_laws(laws):\n",
    "    cleaned_laws = [law.strip() for law in laws if law.strip()]\n",
    "    return cleaned_laws\n",
    "\n",
    "# Main function to extract laws from a PDF\n",
    "def extract_laws_from_pdf(pdf_path):\n",
    "    # Step 1: Load the PDF\n",
    "    text = extract_text_from_pdf(pdf_path)\n",
    "    \n",
    "    # Step 2: Segment the Text\n",
    "    paragraphs = segment_text(text)\n",
    "    \n",
    "    # Step 3: Load the Model and Tokenizer\n",
    "    \"\"\"bnb_config = BitsAndBytesConfig(\n",
    "                                load_in_4bit=True,\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                               )\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B\")\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B\", quantization_config=bnb_config, device_map=\"cuda\")\"\"\"\n",
    "    \n",
    "    # Step 4: Chunk the Text\n",
    "    chunks = chunk_text(paragraphs, tokenizer)\n",
    "    \n",
    "    # Step 5: Identify and Extract Laws\n",
    "    raw_laws = extract_laws(chunks, model, tokenizer)\n",
    "    \n",
    "    # Step 6: Clean and Organize the Extracted Text\n",
    "    cleaned_laws = clean_and_organize_laws(raw_laws)\n",
    "    \n",
    "    return cleaned_laws\n",
    "\n",
    "# Example usage\n",
    "PC_PATH = \"home/utente/Downloads/Codice penale.pdf\"\n",
    "REMOTE_PATH = \"./Codice penale.pdf\"\n",
    "pdf_path = REMOTE_PATH\n",
    "laws = extract_laws_from_pdf(pdf_path)\n",
    "for law in laws:\n",
    "    print(law)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract laws from a file\n",
    "# Function to extract text from a PDF\n",
    "def extract_text_from_pdf(filepath):\n",
    "    with open(filepath, 'rb') as file:\n",
    "        reader = PdfFileReader(file)\n",
    "        text = ''\n",
    "        for page_num in range(reader.numPages):\n",
    "            page = reader.getPage(page_num)\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "# Function to write text to a file\n",
    "def write_to_file(filename, text):\n",
    "    with open(filename, 'w', encoding='utf-8') as file:\n",
    "        file.write(text)\n",
    "\n",
    "# Function to split text into chunks\n",
    "def split_text(text, max_chunk_size=7000, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\n",
    "        \".\\n\",\n",
    "    ],\n",
    "    chunk_size=max_chunk_size, \n",
    "    chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    return text_splitter.create_documents([text])\n",
    "\n",
    "# Function to map (summarize each chunk)\n",
    "def map_summarize_chunks(chunks, map_prompt, llm):\n",
    "    map_chain = SimpleSequentialChain([map_prompt, llm])\n",
    "    chunk_summaries = [map_chain.invoke({\"text\": chunk.page_content}).content for chunk in chunks]\n",
    "    return chunk_summaries\n",
    "\n",
    "# Function to reduce (summarize the combined summaries)\n",
    "def reduce_summary(chunk_summaries, reduce_prompt, llm):\n",
    "    combined_text = \" \".join(chunk_summaries)\n",
    "    reduce_chain = SimpleSequentialChain([reduce_prompt, llm])\n",
    "    final_summary = reduce_chain.invoke({\"text\": combined_text}).content\n",
    "    return final_summary\n",
    "\n",
    "def process_pdf(filepath, map_prompt, reduce_prompt, llm):\n",
    "    text = extract_text_from_pdf(filepath)\n",
    "    chunks = split_text(text)\n",
    "    for i, chunk in enumerate(chunks):\n",
    "        write_to_file(f'chunk{i}.txt', chunk.page_content)\n",
    "    chunk_summaries = map_summarize_chunks(chunks, map_prompt, llm)\n",
    "    final_summary = reduce_summary(chunk_summaries, reduce_prompt, llm)\n",
    "    return final_summary\n",
    "\n",
    "# Default templates\n",
    "map_prompt_template = \\\n",
    "\"\"\"Summarize the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "reduce_prompt_template = \\\n",
    "\"\"\"Summarize the following combined summaries:\n",
    "\n",
    "{text}\n",
    "\n",
    "Final Summary:\"\"\"\n",
    "reduce_prompt = PromptTemplate(template=reduce_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Define the model and the pipeline with 8-bit quantization\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "    load_in_8bit=True,\n",
    "    bnb_8bit_use_double_quant=True,\n",
    "    bnb_8bit_quant_type=\"nf4\",\n",
    "    bnb_8bit_compute_dtype=torch.bfloat16,\n",
    ")\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name, trust_remote_code=True, quantization_config=bnb_config, device_map=\"cuda\")\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "class HuggingFaceTextGenerationChain(Chain):\n",
    "    def __init__(self, generator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        text = inputs['text']\n",
    "        generated_text = self.generator(text, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "        return {\"generated_text\": generated_text}\n",
    "\n",
    "hugging_face_chain = HuggingFaceTextGenerationChain(generator)\n",
    "\n",
    "# Use the chain for summarization\n",
    "result = hugging_face_chain.run({\"text\": \"Tell me a story about artificial intelligence.\"})\n",
    "print(result['generated_text'])\n",
    "\n",
    "# Example other component\n",
    "class DummyChain(Chain):\n",
    "    def _call(self, inputs):\n",
    "        text = inputs['text']\n",
    "        # Perform some dummy operations\n",
    "        processed_text = text.upper()\n",
    "        return {\"text\": processed_text}\n",
    "\n",
    "dummy_chain = DummyChain()\n",
    "hugging_face_chain = HuggingFaceTextGenerationChain(generator)\n",
    "\n",
    "# Combine chains\n",
    "complex_chain = SequentialChain(chains=[dummy_chain, hugging_face_chain])\n",
    "\n",
    "# Use the complex chain with an input\n",
    "result = complex_chain.run({\"text\": \"Describe the future of technology.\"})\n",
    "print(result['generated_text'])\n",
    "\n",
    "reduce_prompt = PromptTemplate(template=reduce_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Path to PDF documents\n",
    "path = \"/home/utente/Desktop/Thesis/Documents/Downloaded\"\n",
    "\n",
    "for filename in os.listdir(path):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(path, filename)\n",
    "        final_summary = process_pdf(pdf_path, map_prompt, reduce_prompt, hugging_face_chain)\n",
    "        #write_to_file('summary.txt', final_summary)\n",
    "        \n",
    "        laws_json = complex_chain.invoke({\"text\": final_summary})\n",
    "        print(f\"Extracted JSON: {laws_json}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
