{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "import json\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoModelForSeq2SeqLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import SimpleSequentialChain, SequentialChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline\n",
    "\n",
    "import bitsandbytes\n",
    "\n",
    "from PyPDF2 import PdfFileReader\n",
    "import lxml.etree as ET\n",
    "import pypandoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "PC_PATH = \"home/utente/Downloads/Codice penale.pdf\"\n",
    "REMOTE_PATH = \"./Codice penale.pdf\"\n",
    "\n",
    "# !!! Write a customized regex to extract the text without words like avv. n. etc.\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text    \n",
    "\n",
    "def extract_text_from_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    return ET.tostring(root, encoding='unicode', method='text')\n",
    "\n",
    "def extract_text_from_rtf(rtf_path):\n",
    "    return pypandoc.convert_file(rtf_path, 'plain', format='rtf')\n",
    "\n",
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def split_text(text, pattern):\n",
    "    parts = re.split(pattern, text, flags=re.MULTILINE)\n",
    "    \n",
    "    parts = [part for part in parts if part]\n",
    "    \n",
    "    if not re.match(pattern, parts[0]):\n",
    "        parts = parts[1:]\n",
    "    \n",
    "    return parts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 Extracting quiz data from local files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dal punto di vista degli effetti, le autorizza...</td>\n",
       "      <td>Consentono ad un soggetto di non adempiere ad ...</td>\n",
       "      <td>Permettono di esercitare facoltà preesistenti.</td>\n",
       "      <td>Accertano l'esistenza dei presupposti richiest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il Capo II della l. n. 241/1990 è riservato al...</td>\n",
       "      <td>Accerta d'ufficio i fatti, disponendo il compi...</td>\n",
       "      <td>Non è mai competente alla valutazione della su...</td>\n",
       "      <td>É solo competente all'indizione delle conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Con riferimento al riesame con esito demolitor...</td>\n",
       "      <td>Quanto a competenza a disporla spetta all'orga...</td>\n",
       "      <td>Non comparta in nessun caso l'obbligo di provv...</td>\n",
       "      <td>Quanto a competenza a disporla non spetta in n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ai sensi dell'art. 80 C.p.a. come avviene la p...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentato nuovamente il ricorso e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entro quale termine le parti devono proporre r...</td>\n",
       "      <td>Nel termine di sessanta giorni decorrente dall...</td>\n",
       "      <td>Nel termine di novanta giorni decorrente dalla...</td>\n",
       "      <td>Nel termine di centoventi giorni decorrente da...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Domanda  \\\n",
       "0  Dal punto di vista degli effetti, le autorizza...   \n",
       "1  Il Capo II della l. n. 241/1990 è riservato al...   \n",
       "2  Con riferimento al riesame con esito demolitor...   \n",
       "3  Ai sensi dell'art. 80 C.p.a. come avviene la p...   \n",
       "4  Entro quale termine le parti devono proporre r...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "0  Consentono ad un soggetto di non adempiere ad ...   \n",
       "1  Accerta d'ufficio i fatti, disponendo il compi...   \n",
       "2  Quanto a competenza a disporla spetta all'orga...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di sessanta giorni decorrente dall...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "0    Permettono di esercitare facoltà preesistenti.    \n",
       "1  Non è mai competente alla valutazione della su...   \n",
       "2  Non comparta in nessun caso l'obbligo di provv...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di novanta giorni decorrente dalla...   \n",
       "\n",
       "                                          Risposta 3  \n",
       "0  Accertano l'esistenza dei presupposti richiest...  \n",
       "1  É solo competente all'indizione delle conferen...  \n",
       "2  Quanto a competenza a disporla non spetta in n...  \n",
       "3  Deve essere presentato nuovamente il ricorso e...  \n",
       "4  Nel termine di centoventi giorni decorrente da...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract questions from the PDF with quiz\n",
    "\n",
    "def extract_questions_answers(text):\n",
    "    qa_pattern = re.compile(r'(\\d+)\\. (.+?)\\n(A\\) .+?)\\n(B\\) .+?)\\n(C\\) .+?)\\n', re.DOTALL)\n",
    "    matches = qa_pattern.findall(text)\n",
    "    \n",
    "    data = []\n",
    "    for match in matches:\n",
    "        question_number, question, answer_a, answer_b, answer_c = match\n",
    "        \n",
    "        # Remove newline characters and clean up answers\n",
    "        question = question.replace('\\n', ' ')\n",
    "        answer_a = answer_a.replace('\\n', ' ').replace('A) ', '')\n",
    "        answer_b = answer_b.replace('\\n', ' ').replace('B) ', '')\n",
    "        answer_c = answer_c.replace('\\n', ' ').replace('C) ', '')\n",
    "        \n",
    "        data.append([question, answer_a, answer_b, answer_c])\n",
    "    \n",
    "    return data\n",
    "\n",
    "PC_PATH = \"home/utente/Downloads/03_diritto_amministrativo.pdf\"\n",
    "REMOTE_PATH = \"./03_diritto_amministrativo.pdf\"\n",
    "text = extract_text_from_pdf(REMOTE_PATH)\n",
    "qa_data = extract_questions_answers(text)\n",
    "\n",
    "df_pdf = pd.DataFrame(qa_data, columns=['Domanda', 'Risposta 1', 'Risposta 2', 'Risposta 3'])\n",
    "df_pdf.to_csv('quiz_pdf.csv', index=False)\n",
    "\n",
    "df_pdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ai sensi dell'art. 240 c.p. è sempre ordinata ...</td>\n",
       "      <td>dei beni che costituiscono il profitto del rea...</td>\n",
       "      <td>dei servizi e degli strumenti informatici o do...</td>\n",
       "      <td>delle cose che costituiscono il movente del reato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ai sensi dell'art. 266 c.p. è punito, se il fa...</td>\n",
       "      <td>fa a militari l'apologia di fatti contrari al ...</td>\n",
       "      <td>istiga gli incaricati di pubblico servizio a v...</td>\n",
       "      <td>istiga i funzionari pubblici a disobbedire ai ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>La pena della multa ex art. 24 c.p. consiste n...</td>\n",
       "      <td>non inferiore a euro 50 né superiore a euro 50...</td>\n",
       "      <td>non inferiore a euro 10 né superiore a euro 50...</td>\n",
       "      <td>non inferiore a euro 25 né superiore a euro 20...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ai sensi dell'art. 7 c.p. è punito secondo la ...</td>\n",
       "      <td>Delitti commessi da pubblici ufficiali a servi...</td>\n",
       "      <td>Delitti contro la personalità del Presidente d...</td>\n",
       "      <td>Delitti di contraffazione della marchiatura de...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tra le pene accessorie per i delitti ex art. 1...</td>\n",
       "      <td>la decadenza o la sospensione dall'esercizio d...</td>\n",
       "      <td>l'estinzione del rapporto di impiego subordina...</td>\n",
       "      <td>l'inabilitazione dagli uffici direttivi delle ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Domanda  \\\n",
       "0  Ai sensi dell'art. 240 c.p. è sempre ordinata ...   \n",
       "1  Ai sensi dell'art. 266 c.p. è punito, se il fa...   \n",
       "2  La pena della multa ex art. 24 c.p. consiste n...   \n",
       "3  Ai sensi dell'art. 7 c.p. è punito secondo la ...   \n",
       "4  Tra le pene accessorie per i delitti ex art. 1...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "0  dei beni che costituiscono il profitto del rea...   \n",
       "1  fa a militari l'apologia di fatti contrari al ...   \n",
       "2  non inferiore a euro 50 né superiore a euro 50...   \n",
       "3  Delitti commessi da pubblici ufficiali a servi...   \n",
       "4  la decadenza o la sospensione dall'esercizio d...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "0  dei servizi e degli strumenti informatici o do...   \n",
       "1  istiga gli incaricati di pubblico servizio a v...   \n",
       "2  non inferiore a euro 10 né superiore a euro 50...   \n",
       "3  Delitti contro la personalità del Presidente d...   \n",
       "4  l'estinzione del rapporto di impiego subordina...   \n",
       "\n",
       "                                          Risposta 3  \n",
       "0  delle cose che costituiscono il movente del reato  \n",
       "1  istiga i funzionari pubblici a disobbedire ai ...  \n",
       "2  non inferiore a euro 25 né superiore a euro 20...  \n",
       "3  Delitti di contraffazione della marchiatura de...  \n",
       "4  l'inabilitazione dagli uffici direttivi delle ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract questions from the JSON file\n",
    "\n",
    "PC_PATH = \"/home/utente/Downloads/domande.json\"\n",
    "REMOTE_PATH = \"domande.json\"\n",
    "with open(REMOTE_PATH, 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions = []\n",
    "answers1 = []\n",
    "answers2 = []\n",
    "answers3 = []\n",
    "\n",
    "# Iterate over each question object in the JSON data\n",
    "for item in data:\n",
    "    question = item['question']\n",
    "    answers = item['answers']\n",
    "    \n",
    "    # Extract each answer and its correctness\n",
    "    correct_answer = None\n",
    "    incorrect_answers = []\n",
    "    for answer in answers:\n",
    "        if answer['right']:\n",
    "            correct_answer = answer['answer']\n",
    "        else:\n",
    "            incorrect_answers.append(answer['answer'])\n",
    "    \n",
    "    answers1.append(correct_answer)\n",
    "    answers2.append(incorrect_answers[0])\n",
    "    answers3.append(incorrect_answers[1])\n",
    "    \n",
    "    questions.append(question)\n",
    "\n",
    "df_json = pd.DataFrame({\n",
    "    'Domanda': questions,\n",
    "    'Risposta 1': answers1,\n",
    "    'Risposta 2': answers2,\n",
    "    'Risposta 3': answers3\n",
    "})\n",
    "\n",
    "df_json.to_csv('quiz_json.csv', index=False)\n",
    "\n",
    "df_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Index</th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Il Capo II della l. n. 241/1990 è riservato al...</td>\n",
       "      <td>Accerta d'ufficio i fatti, disponendo il compi...</td>\n",
       "      <td>Non è mai competente alla valutazione della su...</td>\n",
       "      <td>É solo competente all'indizione delle conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>Ai sensi dell'art. 80 C.p.a. come avviene la p...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentato nuovamente il ricorso e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>Entro quale termine le parti devono proporre r...</td>\n",
       "      <td>Nel termine di sessanta giorni decorrente dall...</td>\n",
       "      <td>Nel termine di novanta giorni decorrente dalla...</td>\n",
       "      <td>Nel termine di centoventi giorni decorrente da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4</td>\n",
       "      <td>A norma di quanto dispone l'art. 133 del C.p.a...</td>\n",
       "      <td>Alla giurisdizione esclusiva del giudice ammin...</td>\n",
       "      <td>Alla giurisdizione esclusiva del giudice ordin...</td>\n",
       "      <td>Alla giurisdizione esclusiva del TAR del Lazio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>5</td>\n",
       "      <td>Consacrando a livello costituzionale i princip...</td>\n",
       "      <td>Moneta, tutela del risparmio e mercati finanzi...</td>\n",
       "      <td>Tutela e sicurezza del lavoro.</td>\n",
       "      <td>Produzione, trasporto e distribuzione nazional...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Index                                            Domanda  \\\n",
       "1      1  Il Capo II della l. n. 241/1990 è riservato al...   \n",
       "3      2  Ai sensi dell'art. 80 C.p.a. come avviene la p...   \n",
       "4      3  Entro quale termine le parti devono proporre r...   \n",
       "7      4  A norma di quanto dispone l'art. 133 del C.p.a...   \n",
       "8      5  Consacrando a livello costituzionale i princip...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "1  Accerta d'ufficio i fatti, disponendo il compi...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di sessanta giorni decorrente dall...   \n",
       "7  Alla giurisdizione esclusiva del giudice ammin...   \n",
       "8  Moneta, tutela del risparmio e mercati finanzi...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "1  Non è mai competente alla valutazione della su...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di novanta giorni decorrente dalla...   \n",
       "7  Alla giurisdizione esclusiva del giudice ordin...   \n",
       "8                    Tutela e sicurezza del lavoro.    \n",
       "\n",
       "                                          Risposta 3  \n",
       "1  É solo competente all'indizione delle conferen...  \n",
       "3  Deve essere presentato nuovamente il ricorso e...  \n",
       "4  Nel termine di centoventi giorni decorrente da...  \n",
       "7   Alla giurisdizione esclusiva del TAR del Lazio.   \n",
       "8  Produzione, trasporto e distribuzione nazional...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes and clean up the data\n",
    "\n",
    "df_merged = pd.concat([df_pdf, df_json], ignore_index=True)\n",
    "df_merged.to_csv('quiz_merged_orig.csv', index=False)\n",
    "\n",
    "# Delete rows which don't contain a number (a law reference)\n",
    "df_merged = df_merged[df_merged['Domanda'].apply(lambda x: bool(re.search(r'\\d', x)))]\n",
    "df_merged = df_merged.drop_duplicates(subset='Domanda')\n",
    "\n",
    "# Add an index colum at the beginning of the dataframe\n",
    "df_merged.insert(0, 'Index', range(1, 1 + len(df_merged)))\n",
    "\n",
    "df_merged.to_csv('quiz_merged.csv', index=False)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2-3 Use of LLMs to extract informations from the quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract laws from a question\n",
    "# Function to quantize and load models\n",
    "def load_quantized_model(model_name):\n",
    "    bnb_config = BitsAndBytesConfig(\n",
    "                                load_in_4bit=True,\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                               )\n",
    "        \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModelForCausalLM.from_pretrained(model_name, quantization_config=bnb_config, device_map=\"cuda\")\n",
    "    return model, tokenizer\n",
    "\n",
    "# Extract laws from a question\n",
    "def extract_laws_from_question(model, tokenizer, quiz_list):\n",
    "    answers = []\n",
    "    model_pipeline = pipeline(\"text-generation\", model=model, tokenizer=tokenizer)\n",
    "\n",
    "    question_prompt = (\n",
    "        \"Ti sottoporrò una domanda di un quiz sul mondo legislativo. \"\n",
    "        \"Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: \"\n",
    "        \"{numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO.\"\n",
    "    )\n",
    "\n",
    "    #for index, row in quiz_list.iterrows():\n",
    "    for index in range(3):\n",
    "        row = quiz_list.iloc[index]\n",
    "        context_prompt = row['Domanda']\n",
    "        full_prompt = f\"{question_prompt} Context: {context_prompt}\"\n",
    "\n",
    "        answer = model_pipeline(full_prompt, max_length=512, do_sample=True, top_p=0.95, num_return_sequences=1)\n",
    "        answers.append(answer[0]['generated_text'])\n",
    "\n",
    "        print(f\"<---- Question {index} ---->\\n\")\n",
    "        print(f\"{full_prompt}\")\n",
    "        print(\"<---- Answer ---->\\n\")\n",
    "        print(f\"{answer}\")\n",
    "\n",
    "    return answers\n",
    "\n",
    "# List of the used models\n",
    "models = {\n",
    "    #\"Saul\": {'model_name': 'Equall/Saul-7B-Instruct-v1', 'context_window': 1024}, #Modello addestrato su testi legali\n",
    "    \"Meta-Llama\": {'model_name': 'meta-llama/Meta-Llama-3-8B-Instruct', 'context_window': 8000},\n",
    "    #\"Falcon-7B\": {'model_name': 'tiiuae/falcon-7b-instruct', 'context_window': 512},\n",
    "    #\"Mixtral-8x22B\": {'model_name': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'context_window': 1024},\n",
    "    #\"Minerva-3B\": {'model_name': 'sapienzanlp/Minerva-3B-base-v1.0', 'context_window': 512}, # Modello italiano della Sapienza\n",
    "    #\"deepset/roberta-base-squad2\" : {'model_name': 'deepset/roberta-base-squad2', 'context_window': 512} # Modello per il question answering\n",
    "}\n",
    "\n",
    "df = pd.read_csv('quiz_merged.csv')\n",
    "output_models = []\n",
    "output_answers = []\n",
    "\n",
    "# Use each model to extract laws from the questions\n",
    "for model_data_key in models.keys():\n",
    "    model_data = models[model_data_key]\n",
    "    print(f\"Model: {model_data['model_name']}\")\n",
    "\n",
    "    model, tokenizer = load_quantized_model(model_data[\"model_name\"])\n",
    "\n",
    "    tmp_answers = extract_laws_from_question(model, tokenizer, df)\n",
    "    \n",
    "    output_answers.extend(tmp_answers)\n",
    "    output_models.extend([model_data[\"model_name\"]] * len(tmp_answers))\n",
    "\n",
    "# Convert the dictionary to a DataFrame\n",
    "df_extracted_laws = pd.DataFrame({\n",
    "    'Model': output_models,\n",
    "    'Question Index': list(range(len(output_answers))),\n",
    "    'Extracted Laws': output_answers\n",
    "})\n",
    "\n",
    "print(df_extracted_laws)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Ti sottoporrò una domanda di un quiz sul mondo legislativo. Estraimi tutte i riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO. Context: Il Capo II della l. n. 241/1990 è riservato alla regolamentazione della figura del  responsabile del procedimento, ovvero del  soggetto al quale è affidato il delicato ruolo di autorità di guida di ciascun procedimento  amministrativo. Esso: 1) coordina e dirige il procedimento, 2) ne esercita la funzione di autorità di guida, 3) ne tiene conto delle esigenze di celerità e di efficacia, 4) ne coordina l\\'attività degli uffici e dei dipendenti incaricati, 5) ne esercita la funzione di autorità di controllo e di garanzia. \\n```json\\n[\\n  {\\n    \"numero della legge\": \"241/1990\",\\n    \"testo della legge\": \"Capo II della l. n. 241/1990\",\\n    \"link alla pagina web\": \"https://www.gazzettaufficiale.it/eli/id/1990/07/24/241/1990\"\\n  }\\n]\\n```\\n\\n### 2. Genera un JSON con le informazioni relative alle leggi sul diritto del lavoro\\n\\nGenera un JSON con le informazioni relative alle leggi sul diritto del lavoro. Estrai tutte le riferimenti a leggi che trovi e generare un JSON con i seguenti campi per ogni legge trovata: {numero della legge, testo della legge, link alla pagina web}. GENERA SOLAMENTE IL JSON, NESSUN TESTO AGGIUNTIVO. Context: La l. n. 300/1974 regola il diritto del lavoro, stabilendo norme per la tutela dei lavoratori e per la regolazione del rapporto di lavoro. La l. n. 108/1996 introduce modifiche alla l. n. 300/1974.\\n```json'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first element of the last column\n",
    "df_extracted_laws['Extracted Laws'][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 - Extract laws from raw files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_cited_laws(text, model, tokenizer):\n",
    "    # Assuming the model is fine-tuned for text extraction tasks or has the capability to handle such queries.\n",
    "    inputs = tokenizer.encode(\"Extract cited laws from the following text: \" + text, return_tensors=\"pt\", max_length=512, truncation=True)\n",
    "    outputs = model.generate(inputs, max_length=512, num_return_sequences=1)\n",
    "    decoded_output = tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "    \n",
    "    cited_laws = decoded_output.split(\"\\n\")\n",
    "    return cited_laws\n",
    "\n",
    "def extract_text_from_file(file_path, file_type):\n",
    "    if file_type == \"pdf\":\n",
    "        text = extract_text_from_pdf(file_path)\n",
    "    elif file_type == \"xml\":\n",
    "        text = extract_text_from_xml(file_path)\n",
    "    elif file_type == \"rtf\":\n",
    "        text = extract_text_from_rtf(file_path)\n",
    "    else:\n",
    "        raise ValueError(\"Unsupported file type\")\n",
    "    return text\n",
    "\n",
    "# Function to split text into chunks\n",
    "def split_text(text, max_chunk_size=7000, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\n",
    "        \"\\n\\n\",\n",
    "    ],\n",
    "    chunk_size=max_chunk_size, \n",
    "    chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    return text_splitter.split_text([text])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:48<00:00, 12.08s/it]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize the model for extracting cited laws\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "                                load_in_4bit=True,\n",
    "                                bnb_4bit_use_double_quant=True,\n",
    "                                bnb_4bit_quant_type=\"nf4\",\n",
    "                                bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                               )\n",
    "        \n",
    "tokenizer = AutoTokenizer.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\"meta-llama/Meta-Llama-3-8B-Instruct\", quantization_config=bnb_config, device_map=\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "Loading checkpoint shards: 100%|██████████| 4/4 [00:54<00:00, 13.67s/it]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Document' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[37], line 19\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filePath \u001b[38;5;129;01min\u001b[39;00m filesPathToAnalyze:\n\u001b[1;32m     18\u001b[0m     fileText \u001b[38;5;241m=\u001b[39m extract_text_from_file(filePath, re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.([a-zA-Z0-9]+)$\u001b[39m\u001b[38;5;124m'\u001b[39m, REMOTE_PATH)\u001b[38;5;241m.\u001b[39mgroup(\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mlower())\n\u001b[0;32m---> 19\u001b[0m     textChunks \u001b[38;5;241m=\u001b[39m \u001b[43msplit_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfileText\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m7500\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m textChunks:\n\u001b[1;32m     21\u001b[0m         citedLaws\u001b[38;5;241m.\u001b[39mappend(extract_cited_laws(chunk, model, tokenizer))\n",
      "Cell \u001b[0;32mIn[36], line 30\u001b[0m, in \u001b[0;36msplit_text\u001b[0;34m(text, max_chunk_size, chunk_overlap)\u001b[0m\n\u001b[1;32m     23\u001b[0m text_splitter \u001b[38;5;241m=\u001b[39m RecursiveCharacterTextSplitter(separators\u001b[38;5;241m=\u001b[39m[\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     25\u001b[0m ],\n\u001b[1;32m     26\u001b[0m chunk_size\u001b[38;5;241m=\u001b[39mmax_chunk_size, \n\u001b[1;32m     27\u001b[0m chunk_overlap\u001b[38;5;241m=\u001b[39mchunk_overlap)\n\u001b[1;32m     29\u001b[0m documents \u001b[38;5;241m=\u001b[39m text_splitter\u001b[38;5;241m.\u001b[39mcreate_documents([text])\n\u001b[0;32m---> 30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[43mdoc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtext\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m doc \u001b[38;5;129;01min\u001b[39;00m documents]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Document' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "# Extract laws from a file\n",
    "\n",
    "\n",
    "filesPathToAnalyze = [REMOTE_PATH]\n",
    "citedLaws = []\n",
    "\n",
    "for filePath in filesPathToAnalyze:\n",
    "    fileText = extract_text_from_file(filePath, re.search(r'\\.([a-zA-Z0-9]+)$', REMOTE_PATH).group(1).lower())\n",
    "    textChunks = split_text(fileText, 7500)\n",
    "    for chunk in textChunks:\n",
    "        citedLaws.append(extract_cited_laws(chunk, model, tokenizer))\n",
    "    \n",
    "print(citedLaws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Generation of a similar law"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
