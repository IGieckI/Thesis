{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import PyPDF2\n",
    "import re\n",
    "\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, pipeline, BitsAndBytesConfig\n",
    "\n",
    "import os\n",
    "import torch\n",
    "from langchain import PromptTemplate\n",
    "from langchain.chains import Chain, SimpleSequentialChain, SequentialChain\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain.llms.huggingface_pipeline import HuggingFacePipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# !!! Write a customized regex to extract the text without words like avv. n. etc.\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text\n",
    "\n",
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def split_text(text, pattern):\n",
    "    parts = re.split(pattern, text, flags=re.MULTILINE)\n",
    "    \n",
    "    parts = [part for part in parts if part]\n",
    "    \n",
    "    if not re.match(pattern, parts[0]):\n",
    "        parts = parts[1:]\n",
    "    \n",
    "    return parts\n",
    "\n",
    "model_names = {\n",
    "    \"LegalBert\": {'model': 'pile-of-law/legalbert-large-1.7M-2', 'context_window': 512}, #Modello molto rapido addestrato su testi legali\n",
    "    \"Saul\": {'model': 'Equall/Saul-7B-Instruct-v1', 'context_window': 1024}, #Modello addestrato su testi legali\n",
    "    \"Meta-Llama\": {'model': 'meta-llama/Meta-Llama-3-8B', 'context_window': 2048},\n",
    "    \"Falcon-7B\": {'model': 'tiiuae/falcon-7b', 'context_window': 512},\n",
    "    \"Mixtral-8x22B\": {'model': 'mistralai/Mixtral-8x22B-Instruct-v0.1', 'context_window': 1024},\n",
    "    \"Minerva-3B\": {'model': 'sapienzanlp/Minerva-3B-base-v1.0', 'context_window': 512}, # Modello italiano della Sapienza\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://172.17.84.11:8804/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://172.17.84.11:8804/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "# Extract questions from the PDF with quiz\n",
    "\n",
    "def extract_questions_answers(text):\n",
    "    qa_pattern = re.compile(r'(\\d+)\\. (.+?)\\n(A\\) .+?)\\n(B\\) .+?)\\n(C\\) .+?)\\n', re.DOTALL)\n",
    "    matches = qa_pattern.findall(text)\n",
    "    \n",
    "    data = []\n",
    "    for match in matches:\n",
    "        question_number, question, answer_a, answer_b, answer_c = match\n",
    "        \n",
    "        # Remove newline characters and clean up answers\n",
    "        question = question.replace('\\n', ' ')\n",
    "        answer_a = answer_a.replace('\\n', ' ').replace('A) ', '')\n",
    "        answer_b = answer_b.replace('\\n', ' ').replace('B) ', '')\n",
    "        answer_c = answer_c.replace('\\n', ' ').replace('C) ', '')\n",
    "        \n",
    "        data.append([question, answer_a, answer_b, answer_c])\n",
    "    \n",
    "    return data\n",
    "\n",
    "\n",
    "text = extract_text_from_pdf(\"/home/utente/Downloads/03_diritto_amministrativo.pdf\")\n",
    "qa_data = extract_questions_answers(text)\n",
    "\n",
    "df_pdf = pd.DataFrame(qa_data, columns=['Domanda', 'Risposta 1', 'Risposta 2', 'Risposta 3'])\n",
    "df_pdf.to_csv('quiz_pdf.csv', index=False)\n",
    "\n",
    "df_pdf.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to connect to the remote Jupyter Server 'http://172.17.84.11:8804/'. Verify the server is running and reachable. (Failed to connect to the remote Jupyter Server 'http://172.17.84.11:8804/'. Verify the server is running and reachable. (Forbidden).)."
     ]
    }
   ],
   "source": [
    "# Extract questions from the JSON file\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "with open('/home/utente/Downloads/domande.json', 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "questions = []\n",
    "answers1 = []\n",
    "answers2 = []\n",
    "answers3 = []\n",
    "\n",
    "# Iterate over each question object in the JSON data\n",
    "for item in data:\n",
    "    question = item['question']\n",
    "    answers = item['answers']\n",
    "    \n",
    "    # Extract each answer and its correctness\n",
    "    correct_answer = None\n",
    "    incorrect_answers = []\n",
    "    for answer in answers:\n",
    "        if answer['right']:\n",
    "            correct_answer = answer['answer']\n",
    "        else:\n",
    "            incorrect_answers.append(answer['answer'])\n",
    "    \n",
    "    answers1.append(correct_answer)\n",
    "    answers2.append(incorrect_answers[0])\n",
    "    answers3.append(incorrect_answers[1])\n",
    "    \n",
    "    questions.append(question)\n",
    "\n",
    "df_json = pd.DataFrame({\n",
    "    'Domanda': questions,\n",
    "    'Risposta 1': answers1,\n",
    "    'Risposta 2': answers2,\n",
    "    'Risposta 3': answers3\n",
    "})\n",
    "\n",
    "df_json.to_csv('quiz_json.csv', index=False)\n",
    "\n",
    "df_json.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Domanda</th>\n",
       "      <th>Risposta 1</th>\n",
       "      <th>Risposta 2</th>\n",
       "      <th>Risposta 3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Il Capo II della l. n. 241/1990 è riservato al...</td>\n",
       "      <td>Accerta d'ufficio i fatti, disponendo il compi...</td>\n",
       "      <td>Non è mai competente alla valutazione della su...</td>\n",
       "      <td>É solo competente all'indizione delle conferen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ai sensi dell'art. 80 C.p.a. come avviene la p...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentata istanza di fissazione d...</td>\n",
       "      <td>Deve essere presentato nuovamente il ricorso e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Entro quale termine le parti devono proporre r...</td>\n",
       "      <td>Nel termine di sessanta giorni decorrente dall...</td>\n",
       "      <td>Nel termine di novanta giorni decorrente dalla...</td>\n",
       "      <td>Nel termine di centoventi giorni decorrente da...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>A norma di quanto dispone l'art. 133 del C.p.a...</td>\n",
       "      <td>Alla giurisdizione esclusiva del giudice ammin...</td>\n",
       "      <td>Alla giurisdizione esclusiva del giudice ordin...</td>\n",
       "      <td>Alla giurisdizione esclusiva del TAR del Lazio.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Consacrando a livello costituzionale i princip...</td>\n",
       "      <td>Moneta, tutela del risparmio e mercati finanzi...</td>\n",
       "      <td>Tutela e sicurezza del lavoro.</td>\n",
       "      <td>Produzione, trasporto e distribuzione nazional...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Domanda  \\\n",
       "1  Il Capo II della l. n. 241/1990 è riservato al...   \n",
       "3  Ai sensi dell'art. 80 C.p.a. come avviene la p...   \n",
       "4  Entro quale termine le parti devono proporre r...   \n",
       "7  A norma di quanto dispone l'art. 133 del C.p.a...   \n",
       "8  Consacrando a livello costituzionale i princip...   \n",
       "\n",
       "                                          Risposta 1  \\\n",
       "1  Accerta d'ufficio i fatti, disponendo il compi...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di sessanta giorni decorrente dall...   \n",
       "7  Alla giurisdizione esclusiva del giudice ammin...   \n",
       "8  Moneta, tutela del risparmio e mercati finanzi...   \n",
       "\n",
       "                                          Risposta 2  \\\n",
       "1  Non è mai competente alla valutazione della su...   \n",
       "3  Deve essere presentata istanza di fissazione d...   \n",
       "4  Nel termine di novanta giorni decorrente dalla...   \n",
       "7  Alla giurisdizione esclusiva del giudice ordin...   \n",
       "8                    Tutela e sicurezza del lavoro.    \n",
       "\n",
       "                                          Risposta 3  \n",
       "1  É solo competente all'indizione delle conferen...  \n",
       "3  Deve essere presentato nuovamente il ricorso e...  \n",
       "4  Nel termine di centoventi giorni decorrente da...  \n",
       "7   Alla giurisdizione esclusiva del TAR del Lazio.   \n",
       "8  Produzione, trasporto e distribuzione nazional...  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Merge the two dataframes and clean up the data\n",
    "\n",
    "df_merged = pd.concat([df_pdf, df_json], ignore_index=True)\n",
    "df_merged.to_csv('quiz_merged_orig.csv', index=False)\n",
    "\n",
    "# Delete rows which don't contain a number (a law reference)\n",
    "df_merged = df_merged[df_merged['Domanda'].apply(lambda x: bool(re.search(r'\\d', x)))]\n",
    "df_merged = df_merged.drop_duplicates(subset='Domanda')\n",
    "\n",
    "# Add an index colum at the beginning of the dataframe\n",
    "df_merged.insert(0, 'Index', range(1, 1 + len(df_merged)))\n",
    "\n",
    "df_merged.to_csv('quiz_merged.csv', index=False)\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading shards:  20%|██        | 12/59 [2:04:09<7:54:10, 605.34s/it] "
     ]
    }
   ],
   "source": [
    "# Extract laws from a question (Mixtral-8x22B)\n",
    "def ask_question(model, question, answers):\n",
    "    #basic_prompt = \"I am going to ask you a quiz question related to the legislative world, choose the correct answer between the possible options: \"\n",
    "    basic_prompt = \"Sto per mostrarti una domanda a carattere legislativo, ricerca tutte le leggi all'interno della domanda e genera un JSON con i seguenti campi per ogni legge trovata {id_domanda,  numero della legge, testo della legge, link alla pagina web}\"\n",
    "    \n",
    "    conversation = [\n",
    "        {\"role\": \"user\", \"content\": basic_prompt + question},\n",
    "        {\"role\": \"assistant\", \"content\": answers}\n",
    "    ]\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(model)\n",
    "    tool_use_prompt = tokenizer.apply_chat_template (\n",
    "        conversation,\n",
    "        chat_template=\"tool_use\",\n",
    "        tools=tools,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True,\n",
    "    )\n",
    "    model = AutoModelForCausalLM.from_pretrained(\"mistralai/Mixtral-8x22B-Instruct-v0.1\", device_map=\"cuda\")\n",
    "\n",
    "    inputs = tokenizer(tool_use_prompt, return_tensors=\"pt\")\n",
    "\n",
    "    outputs = model.generate(**inputs, max_new_tokens=20)\n",
    "    print(tokenizer.decode(outputs[0], skip_special_tokens=True))\n",
    "    \n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred with model Meta-Llama: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.\n",
      "Meta-Llama: An error occurred: At least one of TensorFlow 2.0 or PyTorch should be installed. To install TensorFlow 2.0, read the instructions at https://www.tensorflow.org/install/ To install PyTorch, read the instructions at https://pytorch.org/.\n"
     ]
    }
   ],
   "source": [
    "# Extract laws from a question (other models)\n",
    "def extract_laws_from_question(model, question):\n",
    "    try:\n",
    "        # Load the pipeline for question-answering\n",
    "        qa_pipeline = pipeline(\"question-answering\", model=model, tokenizer=model)\n",
    "        # Ask the question to the model\n",
    "        answer = qa_pipeline(question=question, context=\"I am going to give you a quiz question about the legislative world, from that extract all the laws and generate a JSON with the following fields for each law found {law number, law text, link to the web page}\")\n",
    "        # Store the extracted law from the answer\n",
    "        print(f\"answer: {answer}\")\n",
    "        extracted_laws = answer[\"answer\"]\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred with model {model_name}: {str(e)}\")\n",
    "        extracted_laws[model_name] = f\"An error occurred: {str(e)}\"\n",
    "    return extracted_laws\n",
    "\n",
    "df = pd.read_csv('data.csv')\n",
    "question = \"What laws apply to employment discrimination?\"\n",
    "extracted_laws = {}\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "    print(f\"Index: {index}\")\n",
    "    print(f\"question: {row['Domanda']}, answer_1: {row['Risposta 1']}, answer_2: {row['Risposta 2']}, answer_3: {row['Risposta 3']}\")\n",
    "\n",
    "    for model_name, model_data in model_names.items():\n",
    "        print(f\"{model_name}: {row['Domanda']}\")\n",
    "        extracted_laws[model_data[\"model\"], index] = extract_laws_from_question(model_data[\"model\"], question)\n",
    "        \n",
    "# Convert the dictionary to a DataFrame\n",
    "df_extracted_laws = pd.DataFrame.from_dict(extracted_laws, orient='index')\n",
    "\n",
    "# Rename the columns\n",
    "df_extracted_laws.reset_index(inplace=True)\n",
    "df_extracted_laws.columns = ['Model', 'Question Index', 'Question ID', 'Law Number', 'Law Text', 'Link to the Web Page']\n",
    "\n",
    "# Split the 'Model' column into two separate columns\n",
    "df_extracted_laws[['Model', 'Question Index']] = pd.DataFrame(df_extracted_laws['Model'].tolist(), index=df_extracted_laws.index)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract different laws from .rtf, .xml or pdf files from Normattiva\n",
    "\n",
    "# Function to split text into chunks\n",
    "def split_text(text, max_chunk_size=7000, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\n",
    "        \".\\n\",\n",
    "    ],\n",
    "    chunk_size=max_chunk_size, \n",
    "    chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    return text_splitter.create_documents([text])\n",
    "\n",
    "# Function to map (summarize each chunk)\n",
    "def map_summarize_chunks(chunks):\n",
    "    map_chain = map_prompt | llm# Chain(llm=llm, prompt_template=map_prompt)\n",
    "    chunk_summaries = [map_chain.invoke({\"text\": chunk.page_content}).content for chunk in chunks]\n",
    "    return chunk_summaries\n",
    "\n",
    "# Function to reduce (summarize the combined summaries)\n",
    "def reduce_summary(chunk_summaries):\n",
    "    combined_text = \" \".join(chunk_summaries)\n",
    "    reduce_chain = reduce_prompt | llm #Chain(llm=llm, prompt_template=reduce_prompt)\n",
    "    final_summary = reduce_chain.invoke({\"text\": combined_text}).content\n",
    "    return final_summary\n",
    "\n",
    "def process_pdf(filepath):\n",
    "    text = extract_text_from_pdf(filepath)\n",
    "    chunks = split_text(text)\n",
    "    for i, x in enumerate(chunks):\n",
    "        write_to_file(f'chunk{i}.txt', x.page_content)\n",
    "    chunk_summaries = map_summarize_chunks(chunks)\n",
    "    final_summary = reduce_summary(chunk_summaries)\n",
    "    return final_summary\n",
    "\n",
    "# Default templates\n",
    "map_prompt_template = \\\n",
    "\"\"\"Summarize the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Define the reduce step to summarize the combined summaries\n",
    "reduce_prompt_template = \\\n",
    "\"\"\"Summarize the following combined summaries:\n",
    "\n",
    "{text}\n",
    "\n",
    "Final Summary:\"\"\"\n",
    "\n",
    "# Define the model and the pipeline\n",
    "model_name = \"meta-llama/Meta-Llama-3-8B\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "generator = pipeline('text-generation', model=model, tokenizer=tokenizer)\n",
    "\n",
    "class HuggingFaceTextGenerationChain(Chain):\n",
    "    def __init__(self, generator):\n",
    "        super().__init__()\n",
    "        self.generator = generator\n",
    "\n",
    "    def _call(self, inputs):\n",
    "        text = inputs['text']\n",
    "        generated_text = self.generator(text, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
    "        return {\"generated_text\": generated_text}\n",
    "\n",
    "hugging_face_chain = HuggingFaceTextGenerationChain(generator)\n",
    "chain = SimpleSequentialChain(chains=[hugging_face_chain])\n",
    "\n",
    "# Use the chain\n",
    "result = chain.run({\"text\": \"Tell me a story about artificial intelligence.\"})\n",
    "print(result['generated_text'])\n",
    "\n",
    "\n",
    "# Example other component\n",
    "class DummyChain(Chain):\n",
    "    def _call(self, inputs):\n",
    "        text = inputs['text']\n",
    "        # Perform some dummy operations\n",
    "        processed_text = text.upper()\n",
    "        return {\"text\": processed_text}\n",
    "\n",
    "dummy_chain = DummyChain()\n",
    "hugging_face_chain = HuggingFaceTextGenerationChain(generator)\n",
    "\n",
    "# Combine chains\n",
    "complex_chain = SequentialChain(chains=[dummy_chain, hugging_face_chain])\n",
    "\n",
    "# Use the complex chain with an input\n",
    "result = complex_chain.run({\"text\": \"Describe the future of technology.\"})\n",
    "print(result['generated_text'])\n",
    "    \n",
    "bnb_config = BitsAndBytesConfig(\n",
    "                            load_in_4bit=True,\n",
    "                            bnb_4bit_use_double_quant=True,\n",
    "                            bnb_4bit_quant_type=\"nf4\",\n",
    "                            bnb_4bit_compute_dtype=torch.bfloat16,\n",
    "                            )\n",
    "model = AutoModelForCausalLM.from_pretrained(model, trust_remote_code=True, quantization_config=bnb_config, device_map=\"cuda\")\n",
    "\n",
    "\n",
    "reduce_prompt = PromptTemplate(template=reduce_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "path = \"/home/utente/Desktop/Thesis/Documents/Downloaded\"\n",
    "\n",
    "for filename in os.listdir(os.environ[\"PDF_PATH\"]):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(os.environ[\"PDF_PATH\"], filename)\n",
    "        final_summary = process_pdf(pdf_path)\n",
    "        #write_to_file('summary.txt', final_summary)\n",
    "        \n",
    "        laws_json = chain.invoke({\"text\": final_summary })#\"La corte costituzionale ha dichiarato che la legge 122 e la legge 123 sono antinomie.\"})\n",
    "        print(f\"Extracted JSON: {laws_json}\")\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp",
   "language": "python",
   "name": "tmp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
