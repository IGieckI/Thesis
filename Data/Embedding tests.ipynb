{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    \"Articolo 1: Testo del primo articolo di legge.\",\n",
    "    \"Articolo 2: Testo del secondo articolo di legge.\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(articles, columns=['text'])\n",
    "\n",
    "def get_embeddings(texts, model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "model_names = [\n",
    "    '../Models/SaulLM-7B_model',\n",
    "    '../Models/ChatLaw_model',\n",
    "    '../Models/LLama3-8B_model',\n",
    "    '../Models/MPT-7B_model',\n",
    "    '../Models/Falcon-7B_model'\n",
    "]\n",
    "\n",
    "embeddings_dict = {}\n",
    "for model_name in model_names:\n",
    "    embeddings = get_embeddings(df['text'].tolist(), model_name)\n",
    "    embeddings_dict[model_name] = embeddings\n",
    "\n",
    "# Save embeddings to files\n",
    "for model_name, embeddings in embeddings_dict.items():\n",
    "    np.save(f\"{model_name}_embeddings.npy\", embeddings.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
