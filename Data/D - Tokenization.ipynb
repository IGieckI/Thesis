{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "from pymilvus import FieldSchema, DataType, CollectionSchema, Collection, connections\n",
    "\n",
    "from milvus import default_server"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def connectToMilvus():\n",
    "    try:\n",
    "        connections.connect(\"default\", host=\"localhost\", port=\"19530\")\n",
    "        print(\"Connected to Milvus.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Failed to connect to Milvus: {e}\")\n",
    "        raise\n",
    "\n",
    "def createCollection(name, fields, description):\n",
    "    schema = CollectionSchema(fields, description)\n",
    "    collection = Collection(name, schema, consistency_level=\"Strong\")\n",
    "    return collection\n",
    "\n",
    "def generateEmbeddings(tokenizer, model, docs):\n",
    "    encodings = []\n",
    "    \n",
    "    for doc in data:\n",
    "        # Encode the text to get input ids & attention mask\n",
    "        encoded_input = tokenizer(doc, padding=True, truncation=True, max_length=128, return_tensors='pt')\n",
    "\n",
    "        # Get the embeddings\n",
    "        with torch.no_grad():\n",
    "            model_output = model(**encoded_input)\n",
    "\n",
    "        embeddings.append(model_output.last_hidden_state.mean(dim=1).numpy()[0])\n",
    "\n",
    "    return embeddings\n",
    "\n",
    "def createLawsCollection():\n",
    "    fields = [\n",
    "        FieldSchema(name=\"law_id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=128),\n",
    "        FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_len=50),\n",
    "        FieldSchema(name=\"article\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"comma\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"comma_content\", dtype=DataType.VARCHAR, max_len=5000)\n",
    "    ]    \n",
    "    \n",
    "    return createCollection(\"laws\", fields, \"Collection of laws\")\n",
    "\n",
    "def createQuizCollection():\n",
    "    fields = [\n",
    "        FieldSchema(name=\"quiz_id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=128),\n",
    "        FieldSchema(name=\"question\", dtype=DataType.VARCHAR, max_len=500),\n",
    "        FieldSchema(name=\"answer_1\", dtype=DataType.VARCHAR, max_len=1000),\n",
    "        FieldSchema(name=\"answer_2\", dtype=DataType.VARCHAR, max_len=1000),\n",
    "        FieldSchema(name=\"answer_3\", dtype=DataType.VARCHAR, max_len=1000),\n",
    "        FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_len=50)\n",
    "    ]\n",
    "    \n",
    "    return createCollection(\"quizzes\", fields, \"Collection of quizzes\")\n",
    "\n",
    "def createReferencesCollection():\n",
    "    fields = [\n",
    "        FieldSchema(name=\"reference_id\", dtype=DataType.INT64, is_primary=True, auto_id=True),\n",
    "        FieldSchema(name=\"embedding\", dtype=DataType.FLOAT_VECTOR, dim=128),\n",
    "        FieldSchema(name=\"source\", dtype=DataType.VARCHAR, max_len=50),\n",
    "        FieldSchema(name=\"article\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"comma\", dtype=DataType.INT64),\n",
    "        FieldSchema(name=\"quiz_id\", dtype=DataType.INT64),\n",
    "    ]\n",
    "    \n",
    "    return createCollection(\"references\", fields, \"Collection of references\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/antonelli/.local/lib/python3.8/site-packages/langchain_core/_api/deprecation.py:139: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 0.3.0. An updated version of the class exists in the langchain-huggingface package and should be used instead. To use it run `pip install -U langchain-huggingface` and import as `from langchain_huggingface import HuggingFaceEmbeddings`.\n",
      "  warn_deprecated(\n",
      "/home/antonelli/.local/lib/python3.8/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': 'test', 'pk': 451780400722574584}, page_content='Le banane sono buonissime'), Document(metadata={'source': 'test', 'pk': 451780400722574592}, page_content='Le banane sono buonissime'), Document(metadata={'source': 'test', 'pk': 451780400722574596}, page_content='Le banane sono buonissime'), Document(metadata={'source': 'test', 'pk': 451780400722574588}, page_content='Le banane sono buonissime')]\n"
     ]
    }
   ],
   "source": [
    "# Connect to Milvus\n",
    "try:\n",
    "    connections.connect(\"default\", host=\"0.0.0.0\")\n",
    "except:\n",
    "    default_server.start()\n",
    "    print(\"Milvus server started\")\n",
    "\n",
    "# Initialize the model and tokenizer\n",
    "model_name = \"BAAI/bge-m3\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "# Read laws, quizzes and references csv\n",
    "laws_df = pd.read_csv(\"laws.csv\")\n",
    "quizzes_df = pd.read_csv(\"quizzes.csv\")\n",
    "references_df = pd.read_csv(\"references.csv\")\n",
    "\n",
    "# Create the collections\n",
    "laws_collection = createLawsCollection()\n",
    "quizzes_collection = createQuizCollection()\n",
    "references_collection = createReferencesCollection()\n",
    "\n",
    "# Generate embeddings\n",
    "laws_embeddings = generateEmbeddings(tokenizer, model, laws_df[\"comma_content\"])\n",
    "quizzes_embeddings = generateEmbeddings(tokenizer, model, quizzes_df[\"question\"])\n",
    "references_embeddings = generateEmbeddings(tokenizer, model, references_df[\"comma_content\"])\n",
    "\n",
    "# Insert data into the collections\n",
    "laws_data = []\n",
    "for i in range(len(laws_df)):\n",
    "    laws_data.append([i, laws_embeddings[i], laws_df[\"source\"][i], laws_df[\"article\"][i], laws_df[\"comma\"][i], laws_df[\"comma_content\"][i]])\n",
    "\n",
    "quizzes_data = []\n",
    "for i in range(len(quizzes_df)):\n",
    "    quizzes_data.append([i, quizzes_embeddings[i], quizzes_df[\"question\"][i], quizzes_df[\"answer_1\"][i], quizzes_df[\"answer_2\"][i], quizzes_df[\"answer_3\"][i], quizzes_df[\"source\"][i]])\n",
    "    \n",
    "references_data = []\n",
    "for i in range(len(references_df)):\n",
    "    references_data.append([i, references_embeddings[i], references_df[\"source\"][i], references_df[\"article\"][i], references_df[\"comma\"][i], references_df[\"quiz_id\"][i]])\n",
    "\n",
    "laws_collection.insert(laws_data)\n",
    "quizzes_collection.insert(quizzes_data)\n",
    "references_collection.insert(references_data)\n",
    "\n",
    "# Query the collections\n",
    "query = \"Come sono le banane?\"\n",
    "query_embedding = generateEmbeddings(tokenizer, model, [query])[0]\n",
    "\n",
    "laws_collection.query(query_embedding)\n",
    "quizzes_collection.query(query_embedding)\n",
    "references_collection.query(query_embedding)\n",
    "\n",
    "# Close the connection\n",
    "connections.disconnect(\"default\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Milvus' object has no attribute 'list_collections'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m client \u001b[38;5;241m=\u001b[39m Milvus(connection_args\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhost\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m127.0.0.1\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mport\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m19530\u001b[39m\u001b[38;5;124m\"\u001b[39m}, embedding_function\u001b[38;5;241m=\u001b[39membedder)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# List all collections\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m collections \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist_collections\u001b[49m()\n\u001b[1;32m      6\u001b[0m \u001b[38;5;66;03m# Print all collections and their stats\u001b[39;00m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m collection_name \u001b[38;5;129;01min\u001b[39;00m collections:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Milvus' object has no attribute 'list_collections'"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "client = Milvus(connection_args={\"host\": \"127.0.0.1\", \"port\": \"19530\"}, embedding_function=embedder)\n",
    "\n",
    "# List all collections\n",
    "collections = client.list_collections()\n",
    "\n",
    "# Print all collections and their stats\n",
    "for collection_name in collections:\n",
    "    print(f\"Collection name: {collection_name}\")\n",
    "    stats = client.get_collection_stats(collection_name)\n",
    "    print(f\"Stats: {stats}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset into Milvus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from langchain_text_splitters import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import Milvus\n",
    "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "from pymilvus import connections\n",
    "\n",
    "from milvus import default_server\n",
    "\n",
    "DEFAULT_SAVE_DIR = os.getcwd() + \"/work/documents/\"\n",
    "CODICE_PENALE_DIR = DEFAULT_SAVE_DIR + \"Codice_Penale.csv\"\n",
    "REFERENCES_CSV_FILE = DEFAULT_SAVE_DIR + \"quiz_references.csv\"\n",
    "\n",
    "default_server.start()\n",
    "connections.connect(\"default\", host=\"0.0.0.0\")\n",
    "\n",
    "df = pd.read_csv(CODICE_PENALE_DIR)\n",
    "data = (df.iloc[:, 0] + \" \" + df.iloc[:, 1]).tolist()\n",
    "\n",
    "# Process the list to create Document objects\n",
    "documents = []\n",
    "for document in data:\n",
    "    documents.append(Document(page_content=document, metadata={\"source\": \"csv\"}))\n",
    "\n",
    "embedder = HuggingFaceEmbeddings(model_name=\"BAAI/bge-m3\",\n",
    "                                     model_kwargs={\"device\": \"cuda\"})\n",
    "\n",
    "# Add the documents to the Milvus database\n",
    "vector_db = Milvus.from_documents(\n",
    "        documents,\n",
    "        embedder, \n",
    "        connection_args={\"host\":  \"127.0.0.1\", \"port\": \"19530\"},\n",
    "        collection_name=\"csv_data\"\n",
    "    )\n",
    "\n",
    "# Load the references\n",
    "df_queries = pd.read_csv(REFERENCES_CSV_FILE)\n",
    "\n",
    "queries = df_queries.iloc[:, 1].tolist()\n",
    "df_results = pd.DataFrame(columns=['Question', 'Answer'])\n",
    "\n",
    "# For each query in the list, query the database and store the question and answer in the DataFrame\n",
    "for query in queries:\n",
    "    docs = vector_db.similarity_search(query)\n",
    "    answer = docs[0].page_content if docs else 'No match found'\n",
    "    df_results = df_results.append({'Question': query, 'Answer': answer}, ignore_index=True)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
