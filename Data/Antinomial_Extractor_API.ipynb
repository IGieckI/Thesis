{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain pdfplumber langchain-openai langchail-text-spliteters > /dev/null\n",
    "\n",
    "import os\n",
    "import re\n",
    "import pdfplumber\n",
    "import pandas as pd\n",
    "from langchain import PromptTemplate\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "# RTF -> article extraction\n",
    "from striprtf.striprtf import rtf_to_text\n",
    "from collections import defaultdict\n",
    "\n",
    "# Testing embedding models\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"e28b35965f744d38b464c69d32496500\"\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://mg-openai-adv.openai.azure.com/\"\n",
    "os.environ[\"PDF_PATH\"] = \"/home/utente/Scaricati/Legislative pdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model and the prompt template through AzureChatOpenAI\n",
    "\n",
    "# GPT3.5: mg-gpt-35-turbo-16k\n",
    "# GPT4: mg-gpt-4-0613\n",
    "llm = AzureChatOpenAI(deployment_name=\"mg-gpt-35-turbo-16k\", temperature=0.9)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    You are given a text from a PDF that contains sentences about two antinomial laws.\n",
    "    Your task is to extract the law numbers and determine if they are antinomial.\n",
    "    \n",
    "    Text: {text}\n",
    "    \n",
    "    Please provide a JSON response with the following keys:\n",
    "    - first_law: the number of the first law\n",
    "    - second_law: the number of the second law\n",
    "    - are_antinomial: 1 if the laws are antinomial, 0 if they are not, 2 if it is unclear\n",
    "    \"\"\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant specialized in analyzing legal texts.\"),\n",
    "    (\"user\", prompt_template)\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/utente/.local/lib/python3.10/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.1965, -0.4241, -0.0790,  ..., -0.2015, -0.1456,  0.3158],\n",
       "         [-0.2645, -0.2345,  0.0482,  ...,  0.6902,  0.1312, -0.4591],\n",
       "         [-0.2937, -0.1044, -0.3545,  ...,  0.4051,  0.0844,  0.3564],\n",
       "         ...,\n",
       "         [ 0.1385,  0.0258,  0.0761,  ..., -0.0405, -0.1984,  0.9173],\n",
       "         [ 0.2290,  0.0651, -0.4753,  ...,  0.0164,  0.2266,  0.1565],\n",
       "         [-0.1964, -0.4236, -0.0793,  ..., -0.2017, -0.1453,  0.3159]]],\n",
       "       grad_fn=<NativeLayerNormBackward0>), pooler_output=tensor([[-5.1989e-01,  4.3836e-01,  9.4956e-01,  1.8751e-01,  4.7849e-01,\n",
       "          1.6745e-01, -5.9398e-02, -1.8771e-01,  8.6579e-01,  4.0117e-01,\n",
       "          6.4372e-01, -1.2341e-01,  5.2440e-01, -8.9162e-01, -5.6513e-01,\n",
       "          3.0558e-01, -4.1909e-01,  1.4944e-01, -2.8861e-01, -1.4434e-01,\n",
       "          1.6670e-01, -2.7394e-01,  9.1846e-01,  1.0344e-01,  6.8153e-02,\n",
       "         -7.6606e-01, -8.3362e-02,  8.0751e-01, -1.5699e-01, -3.1320e-01,\n",
       "         -1.9290e-01, -4.6169e-04,  2.4571e-01,  2.6212e-01,  9.5055e-01,\n",
       "         -5.4232e-01,  2.7516e-01,  1.5924e-01,  1.5112e-01,  2.0451e-01,\n",
       "          6.3865e-02, -2.0108e-01, -4.3858e-01, -9.1448e-01, -2.0282e-01,\n",
       "          1.8161e-01,  8.5360e-01, -9.1071e-02,  3.0596e-01, -8.9732e-01,\n",
       "         -8.8094e-01, -9.1589e-01, -7.1119e-01, -3.2330e-01, -4.6016e-01,\n",
       "          4.4823e-01, -1.2561e-01,  9.7337e-02,  2.2532e-01,  3.9268e-01,\n",
       "          1.0013e-01,  1.0155e-02,  6.6226e-01, -5.1579e-01, -9.7520e-01,\n",
       "         -9.5202e-01,  2.0261e-01,  1.2713e-01, -9.4285e-02, -1.9513e-01,\n",
       "          1.3002e-02, -4.3699e-01, -1.4745e-01,  6.8362e-01, -9.4080e-01,\n",
       "         -2.8103e-01, -2.8404e-02, -6.2725e-01, -5.6556e-01,  7.6071e-01,\n",
       "         -7.8214e-01, -9.4046e-01,  2.3408e-02,  9.4857e-01, -9.7803e-01,\n",
       "          6.1930e-01,  2.6983e-01,  4.4414e-01,  8.6496e-01, -7.9076e-02,\n",
       "         -5.9314e-02,  3.2260e-01, -9.6333e-01,  1.5371e-01,  9.6374e-01,\n",
       "          1.6607e-01,  3.6651e-01,  7.1164e-02,  1.0078e-02,  2.2645e-02,\n",
       "         -1.0586e-01,  5.8462e-01,  4.0900e-02, -1.1869e-01,  2.3144e-02,\n",
       "         -3.1603e-01,  2.8233e-01, -1.7894e-04, -9.0217e-01, -4.4050e-01,\n",
       "          2.3158e-01, -2.1057e-01, -3.9800e-01,  4.2613e-02, -2.6714e-01,\n",
       "          2.5461e-01,  9.5511e-02, -3.1759e-01,  3.4417e-02, -1.5595e-01,\n",
       "          5.5973e-01, -4.2871e-02, -1.3702e-01,  1.0312e-01, -3.6578e-01,\n",
       "         -5.1317e-02,  9.3982e-01,  5.8025e-01,  3.2964e-01,  1.1839e-01,\n",
       "          9.0903e-01, -9.9199e-02,  3.8577e-01,  2.4765e-02,  2.0914e-01,\n",
       "          6.0134e-01,  8.3092e-02,  3.4581e-01,  8.1206e-02, -2.1671e-01,\n",
       "          9.4811e-01,  9.0105e-01, -8.5740e-01, -4.7724e-01, -5.4261e-01,\n",
       "         -4.3765e-02,  4.6935e-01, -3.0200e-02, -2.9994e-01, -9.0868e-01,\n",
       "         -3.0413e-01,  4.2804e-01,  9.5949e-01,  2.3159e-01,  2.0141e-02,\n",
       "          2.7850e-01,  9.6883e-01,  9.2945e-01,  9.1404e-01,  2.9513e-03,\n",
       "          3.4355e-01,  3.9665e-01,  2.7150e-03, -2.6204e-01,  9.4324e-01,\n",
       "         -8.0913e-02, -4.0803e-01, -6.4255e-02, -3.8754e-01,  9.4870e-01,\n",
       "         -5.4507e-01, -2.6882e-01,  9.7343e-01, -6.0163e-01,  2.0877e-01,\n",
       "          8.5971e-02, -1.8436e-01,  3.6884e-01,  1.0942e-01, -7.6247e-01,\n",
       "         -3.1722e-01, -8.6251e-01, -1.0580e-01,  1.7189e-01,  5.5232e-01,\n",
       "          3.1453e-01,  2.3900e-01, -4.2256e-01, -2.0522e-01, -9.6837e-01,\n",
       "          1.4093e-01,  9.4775e-01, -8.8854e-01, -2.7039e-01, -8.7191e-02,\n",
       "          4.2533e-01,  4.7908e-01, -3.6477e-01,  5.2480e-01, -3.7882e-01,\n",
       "         -9.2895e-06, -6.4896e-01, -4.5671e-01, -2.5463e-01, -9.6681e-01,\n",
       "          6.4490e-01, -6.6823e-01, -3.2405e-01,  1.8263e-01, -2.1741e-01,\n",
       "          5.8082e-02, -8.9405e-01, -2.0374e-01,  2.7417e-01,  1.6941e-01,\n",
       "         -6.0146e-01, -2.3321e-01,  4.4676e-02,  1.2978e-01,  3.5861e-01,\n",
       "          5.5481e-01,  3.4473e-01, -8.3486e-01,  2.8632e-01,  4.1125e-01,\n",
       "          5.0118e-01, -3.5294e-01, -4.5179e-01, -2.1588e-01,  3.1792e-01,\n",
       "         -3.1885e-01, -6.1068e-01,  1.6123e-02, -6.2104e-02, -5.7596e-01,\n",
       "          1.9091e-01, -1.9614e-01, -5.2358e-01,  1.0686e-01, -1.5563e-01,\n",
       "         -5.1512e-02,  3.9726e-01, -1.6697e-02,  4.4997e-01,  3.6380e-01,\n",
       "          9.2251e-01, -1.1524e-01,  9.6484e-01, -1.1100e-01, -8.4570e-01,\n",
       "         -9.3939e-01,  3.2124e-01,  4.0300e-02,  8.5030e-01, -1.3775e-01,\n",
       "         -1.9319e-02,  8.7386e-02, -5.2139e-01, -7.9684e-01,  5.8118e-01,\n",
       "         -1.8243e-01, -6.1567e-01,  1.0335e-01, -7.6236e-01,  4.1457e-01,\n",
       "          2.0375e-01,  4.2589e-01, -7.2905e-01, -2.1211e-01, -1.3786e-01,\n",
       "          3.2693e-01,  4.9320e-01,  8.5052e-03,  5.0107e-01, -2.1117e-01,\n",
       "         -1.3711e-01,  9.7219e-01, -4.2219e-01, -3.1409e-02, -3.8407e-01,\n",
       "         -1.1439e-01,  2.1291e-01,  8.2885e-01, -2.1274e-01, -9.7065e-01,\n",
       "          2.6934e-01, -2.9605e-01,  3.1877e-01,  4.4865e-01, -3.6041e-01,\n",
       "          2.3192e-01,  1.0814e-01,  9.0763e-01,  3.3908e-01,  3.2712e-01,\n",
       "         -2.5702e-01,  5.3714e-01,  1.2048e-01, -4.0374e-02, -5.9109e-01,\n",
       "         -8.8349e-01, -5.1531e-01,  9.2530e-02,  7.6910e-01,  3.9463e-01,\n",
       "          2.8616e-01, -3.1695e-01, -8.9636e-01,  2.5198e-01,  5.2954e-01,\n",
       "          2.2853e-01, -1.0494e-01, -2.1575e-01, -4.7198e-01,  9.4388e-01,\n",
       "          2.7295e-01,  8.7350e-01,  2.7598e-01,  3.1045e-01, -7.6678e-02,\n",
       "          2.6166e-01,  4.6966e-01,  8.7212e-02, -2.0557e-01, -6.3567e-01,\n",
       "          6.5977e-01,  1.5178e-01, -9.4879e-01, -3.2209e-01, -1.3760e-01,\n",
       "          5.8998e-02, -1.0339e-01,  1.1438e-01, -9.5080e-01, -6.7948e-02,\n",
       "          1.6038e-01, -1.9670e-01, -1.8376e-01, -3.1978e-01, -9.1307e-01,\n",
       "          9.1081e-01,  8.2408e-02,  6.7385e-01,  1.3205e-01, -8.0415e-01,\n",
       "         -7.7874e-01, -3.4259e-01, -6.2513e-02, -4.7630e-01,  8.3183e-03,\n",
       "         -1.6283e-01, -7.7816e-01,  1.7988e-01, -2.1030e-01, -2.0904e-01,\n",
       "          6.7932e-02,  3.8300e-01, -1.0596e-02, -4.2174e-01,  2.5651e-01,\n",
       "          9.3167e-01,  8.8851e-01,  5.9920e-01, -6.2142e-01,  2.6991e-01,\n",
       "          1.3165e-01, -2.9248e-01,  7.0356e-03,  6.1059e-01,  4.6511e-02,\n",
       "          3.5833e-01, -1.6744e-01,  6.7572e-01, -3.5654e-01, -2.8097e-01,\n",
       "         -1.4664e-01,  2.0447e-01,  2.4796e-01, -4.5707e-01,  2.0254e-01,\n",
       "         -3.4206e-01,  2.0097e-03,  3.4306e-02,  8.8877e-01,  1.2869e-01,\n",
       "          1.9893e-01, -4.3801e-01, -4.4182e-01,  2.0714e-01, -2.7697e-01,\n",
       "         -2.6048e-01, -3.1615e-01, -8.1278e-01, -1.2980e-01, -1.6112e-01,\n",
       "          8.4037e-01, -3.0771e-01, -3.3491e-01,  1.5025e-01, -1.8668e-01,\n",
       "         -3.6432e-02, -5.7256e-01, -6.9290e-01,  6.5864e-01, -4.9624e-01,\n",
       "          3.9550e-01, -2.3639e-01,  2.3653e-01, -8.4645e-01, -5.7662e-02,\n",
       "         -5.0399e-01, -3.9431e-01, -7.9730e-01, -4.9384e-01, -2.4407e-01,\n",
       "         -9.5697e-01, -3.1777e-01,  4.8863e-01,  3.0866e-01,  3.3034e-01,\n",
       "          9.6257e-01,  1.8778e-01,  4.2213e-01, -2.4254e-01, -8.2450e-01,\n",
       "          2.8787e-01,  2.1842e-01,  1.4761e-01, -9.2920e-01, -1.5084e-01,\n",
       "         -5.4530e-03, -2.8155e-01, -9.3672e-01, -7.9504e-01, -3.5620e-01,\n",
       "          7.4485e-01, -2.5880e-01,  7.0231e-01, -1.3241e-01, -9.4152e-02,\n",
       "         -2.0398e-02,  9.7239e-01,  4.4087e-01,  4.1293e-01, -1.2087e-01,\n",
       "         -9.3984e-01,  8.3859e-02,  2.3641e-01, -8.3294e-01,  9.4947e-01,\n",
       "         -1.6831e-01,  1.5766e-01,  1.5826e-01, -6.6804e-02, -2.1823e-02,\n",
       "         -8.0992e-01,  1.6685e-01, -1.5893e-01,  9.0989e-01,  5.7655e-01,\n",
       "         -1.3493e-03, -1.4397e-01,  4.7194e-02, -6.2713e-01,  9.2362e-01,\n",
       "          1.7642e-01,  1.4982e-01,  2.1418e-01,  2.0779e-01,  1.5556e-01,\n",
       "         -1.6593e-01, -4.6232e-01, -2.1028e-01, -7.1309e-01,  1.9502e-01,\n",
       "         -6.2406e-01, -2.5005e-01,  1.5738e-01, -1.4969e-01,  5.8830e-02,\n",
       "         -9.5481e-01, -1.7850e-02,  9.5494e-01,  9.3357e-01,  1.8265e-01,\n",
       "         -3.1874e-01,  5.7927e-01, -9.0573e-01, -9.6539e-01, -2.2233e-01,\n",
       "          1.7055e-01, -1.3194e-01,  4.2422e-01, -5.5417e-01,  3.5628e-01,\n",
       "          3.9866e-01,  4.7547e-01,  2.4079e-01,  3.9976e-01,  3.7542e-01,\n",
       "          1.8973e-01, -7.9480e-01,  1.1957e-01,  8.3442e-02,  8.6364e-02,\n",
       "          3.7379e-01, -3.3169e-01, -9.8488e-01,  8.5901e-02, -4.1995e-01,\n",
       "          2.1211e-01,  2.3003e-01,  5.4509e-01,  3.1798e-01,  4.6073e-01,\n",
       "          1.9763e-01, -6.5682e-02, -2.3093e-03,  4.0262e-01,  3.3776e-01,\n",
       "          4.3360e-02,  5.1153e-01, -3.4394e-01, -2.9486e-01, -7.8779e-01,\n",
       "          4.4300e-01, -2.3933e-01, -3.2026e-01,  3.4254e-01, -9.1650e-01,\n",
       "          1.6883e-02, -5.9551e-01,  5.5659e-02,  5.7058e-02, -3.2352e-01,\n",
       "         -1.2693e-01, -1.8532e-01,  1.1475e-01,  5.0058e-01, -9.1481e-01,\n",
       "          8.9633e-01, -7.4859e-01, -8.9010e-01, -7.9506e-01,  2.8096e-01,\n",
       "         -9.3886e-01,  3.1231e-01, -8.7205e-01,  4.6122e-02,  6.2712e-01,\n",
       "          4.3240e-02,  4.5287e-01, -8.7308e-02,  2.1888e-01,  2.6743e-01,\n",
       "          1.0119e-01, -2.1150e-01,  2.2998e-01,  2.5182e-01, -4.6279e-02,\n",
       "         -3.6226e-01, -3.5381e-01, -5.0895e-01,  2.5465e-01,  9.8359e-03,\n",
       "         -4.9101e-01, -3.6180e-01,  5.1082e-01, -2.0620e-03,  1.4725e-02,\n",
       "          5.5103e-01, -3.4852e-03, -8.7420e-02,  6.8870e-01, -4.0710e-01,\n",
       "          8.5310e-01, -4.2964e-02, -9.2481e-01, -1.2049e-01, -5.0314e-01,\n",
       "         -3.4606e-01,  1.9226e-01, -2.3693e-02,  9.5015e-01,  9.2313e-01,\n",
       "         -1.9109e-01,  2.1136e-01,  8.8282e-01,  1.1617e-01, -2.9003e-01,\n",
       "          4.6332e-01, -2.7935e-01,  9.5755e-01,  2.2942e-01, -2.7091e-01,\n",
       "         -6.4991e-01, -7.8344e-03,  9.9732e-02,  2.0352e-02,  1.0677e-01,\n",
       "          1.7130e-01, -9.5354e-01,  5.6537e-01, -3.4094e-02,  1.0768e-01,\n",
       "         -2.3934e-01,  6.7172e-01,  2.5458e-02, -9.4528e-02, -2.6476e-01,\n",
       "          3.9535e-01, -1.2752e-01, -9.9965e-02, -1.8404e-01, -8.1790e-02,\n",
       "          1.1087e-01,  2.2947e-01, -1.6048e-01, -8.8846e-01, -1.0949e-01,\n",
       "         -4.3264e-01, -2.7618e-01,  3.4604e-01,  1.1748e-01, -2.0806e-01,\n",
       "          8.8024e-02,  8.1486e-02,  9.1159e-02, -7.1067e-01, -1.2770e-01,\n",
       "          2.7956e-01, -1.2038e-01,  1.9591e-01, -3.9657e-02,  2.3719e-02,\n",
       "          5.3525e-01,  3.1782e-01,  1.5959e-01,  1.4218e-01,  8.4015e-02,\n",
       "          9.4000e-01,  3.3370e-01,  4.9016e-01,  8.7424e-01, -1.4860e-02,\n",
       "          2.3414e-01, -5.2966e-02, -7.5107e-01, -6.5130e-01, -4.7220e-01,\n",
       "          4.0004e-02, -2.2612e-01, -2.4786e-01, -6.1170e-02,  8.3921e-02,\n",
       "          7.3604e-01, -4.2154e-01, -1.2449e-01, -9.6847e-01, -7.7974e-01,\n",
       "         -5.0052e-01,  3.6433e-01, -1.2028e-01,  1.5652e-01,  6.2664e-01,\n",
       "          5.2994e-01,  2.9069e-01, -5.4523e-01,  2.4979e-01, -3.8882e-01,\n",
       "          6.7668e-02, -1.0514e-01,  6.4622e-01,  9.4472e-01,  3.5762e-01,\n",
       "          7.5578e-01,  4.0461e-02,  8.3877e-01,  1.0245e-01,  8.1041e-02,\n",
       "         -7.0783e-01,  1.3694e-01,  9.1349e-01, -2.9866e-01,  1.7246e-01,\n",
       "         -2.3053e-01, -4.1440e-01, -9.9334e-02, -3.5816e-02,  8.1975e-02,\n",
       "          2.6582e-01, -4.9705e-01,  8.7684e-01, -1.4803e-01,  8.9475e-01,\n",
       "         -3.9210e-01,  8.4950e-01, -6.1057e-01, -6.2066e-01, -5.8812e-01,\n",
       "          9.3492e-01,  8.0195e-02, -1.9442e-01,  4.6397e-01,  8.2908e-01,\n",
       "         -1.0466e-01, -2.0177e-01,  5.0524e-01,  1.2556e-01, -3.8062e-01,\n",
       "         -3.3845e-01,  4.6710e-01,  3.0592e-01,  3.4524e-01,  3.0220e-01,\n",
       "          7.5328e-01, -2.6149e-01,  2.1824e-03, -1.9864e-01, -5.3466e-02,\n",
       "          8.6421e-01, -4.7730e-01,  3.6481e-01,  5.3830e-01,  9.6853e-01,\n",
       "         -3.6416e-01, -2.5650e-01,  5.0310e-01, -9.2346e-01, -1.2880e-01,\n",
       "          2.1984e-01, -2.0175e-01,  3.9533e-01, -6.4923e-01,  1.4331e-01,\n",
       "          2.6500e-01,  2.3554e-01, -1.2315e-01, -8.0430e-01,  9.6634e-01,\n",
       "          9.5749e-01,  3.4065e-01, -2.9019e-01,  3.3119e-01,  7.9875e-01,\n",
       "          8.3152e-01, -1.9000e-01,  7.0853e-01, -9.2869e-01,  9.6772e-01,\n",
       "         -4.7514e-01,  1.4228e-01, -4.9397e-01,  2.9023e-01,  3.2397e-02,\n",
       "         -9.0897e-01, -1.2171e-01, -2.6493e-01,  5.2625e-01,  7.8725e-01,\n",
       "         -4.6555e-01, -8.7411e-02, -4.9002e-01,  9.2914e-01,  1.5780e-01,\n",
       "          4.0597e-01, -1.6770e-01, -4.6098e-01]], grad_fn=<TanhBackward0>), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set up the model and the prompt template through Hugging Face's API (Italian-Legal-Bert)\n",
    "\n",
    "from transformers import AutoModel, AutoTokenizer\n",
    "model_name = \"nlpaueb/legal-bert-base-uncased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n",
    "\n",
    "text = \"Tell me something about the Italian legal system: \"\n",
    "inputs = tokenizer(text, return_tensors=\"pt\")\n",
    "outputs = model(**inputs)\n",
    "\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions\n",
    "\n",
    "# !!! Write a customized regex to extract the text without words like avv. n. etc.\n",
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    with pdfplumber.open(pdf_path) as pdf:\n",
    "        text = ''\n",
    "        for page in pdf.pages:\n",
    "            text += page.extract_text() + '\\n'\n",
    "    write_to_file('summary.txt', text)\n",
    "    return text\n",
    "\n",
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "    \n",
    "def split_text(text, pattern):\n",
    "    parts = re.split(pattern, text, flags=re.MULTILINE)\n",
    "    \n",
    "    parts = [part for part in parts if part]\n",
    "    \n",
    "    if not re.match(pattern, parts[0]):\n",
    "        parts = parts[1:]\n",
    "    \n",
    "    return parts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Part 1: Law No. 123\n",
      "Part 2:  is the first law. More text. \n",
      "Part 3: Law No. 456\n",
      "Part 4:  is the second law.\n"
     ]
    }
   ],
   "source": [
    "# Example text\n",
    "text2 = \"Some introduction text. Law No. 123 is the first law. More text. Law No. 456 is the second law.\"\n",
    "\n",
    "# Define the regex pattern to split on and capture\n",
    "pattern = r'(Law No\\. \\d+)'\n",
    "\n",
    "# Display the results\n",
    "for i, part in enumerate(split_text(text2, pattern)):\n",
    "    print(f\"Part {i+1}: {part}\")\n",
    "\n",
    "# If you need to process the parts further, you can do so here.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wow', ' something ', 'wow', ' asdfsadf ', 'wow', ' sdfcsdcfsdcsadcsd']\n"
     ]
    }
   ],
   "source": [
    "print(split_text(\"something wow something wow asdfsadf wow sdfcsdcfsdcsadcsd\", r'(wow)'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute scraping in the HTML file\n",
    "from bs4 import BeautifulSoup\n",
    "from urllib.request import Request, urlopen\n",
    "import re\n",
    "\n",
    "with open('./Normattiva - Export.html') as f:\n",
    "    html_page = f.read()\n",
    "\n",
    "soup = BeautifulSoup(html_page, 'html.parser')\n",
    "\n",
    "for tag in soup.find_all('div', attrs={'class': 'container ContentHtmlExp'}):\n",
    "    #print(tag)\n",
    "    print(tag.text)\n",
    "    print(\"------------------------------\")\n",
    "\n",
    "\"\"\"\n",
    "links = []\n",
    "\n",
    "for link in soup.findAll('div'):\n",
    "    links.append(link.get('href'))\n",
    "\n",
    "print(links)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libri: 4, Titoli: 25, Capitoli: 60, Sezioni: 57, Articoli: 450\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>libro</th>\n",
       "      <th>titolo</th>\n",
       "      <th>capo</th>\n",
       "      <th>sezione</th>\n",
       "      <th>numero_articolo</th>\n",
       "      <th>titolo_articolo</th>\n",
       "      <th>testo_articolo</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LIBRO PRIMO DISPOSIZIONI GENERALI</td>\n",
       "      <td>TITOLO I DEGLI ORGANI GIUDIZIARI</td>\n",
       "      <td>CAPO I Del giudice</td>\n",
       "      <td>Sezione I Della giurisdizione e della competen...</td>\n",
       "      <td>1</td>\n",
       "      <td>(Giurisdizione dei giudici ordinari).</td>\n",
       "      <td>La giurisdizione civile, salvo speciali dispos...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LIBRO PRIMO DISPOSIZIONI GENERALI</td>\n",
       "      <td>TITOLO I DEGLI ORGANI GIUDIZIARI</td>\n",
       "      <td>CAPO I Del giudice</td>\n",
       "      <td>Sezione I Della giurisdizione e della competen...</td>\n",
       "      <td>2</td>\n",
       "      <td>((ARTICOLO ABROGATO DALLA L. 31 MAGGIO 1995, N...</td>\n",
       "      <td>PARSE ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LIBRO PRIMO DISPOSIZIONI GENERALI</td>\n",
       "      <td>TITOLO I DEGLI ORGANI GIUDIZIARI</td>\n",
       "      <td>CAPO I Del giudice</td>\n",
       "      <td>Sezione I Della giurisdizione e della competen...</td>\n",
       "      <td>3</td>\n",
       "      <td>((ARTICOLO ABROGATO DALLA L. 31 MAGGIO 1995, N...</td>\n",
       "      <td>PARSE ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LIBRO PRIMO DISPOSIZIONI GENERALI</td>\n",
       "      <td>TITOLO I DEGLI ORGANI GIUDIZIARI</td>\n",
       "      <td>CAPO I Del giudice</td>\n",
       "      <td>Sezione I Della giurisdizione e della competen...</td>\n",
       "      <td>4</td>\n",
       "      <td>((ARTICOLO ABROGATO DALLA L. 31 MAGGIO 1995, N...</td>\n",
       "      <td>PARSE ERROR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LIBRO PRIMO DISPOSIZIONI GENERALI</td>\n",
       "      <td>TITOLO I DEGLI ORGANI GIUDIZIARI</td>\n",
       "      <td>CAPO I Del giudice</td>\n",
       "      <td>Sezione I Della giurisdizione e della competen...</td>\n",
       "      <td>5</td>\n",
       "      <td>(Momento determinante della giurisdizione e de...</td>\n",
       "      <td>La giurisdizione e la competenza si determinan...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                libro                             titolo  \\\n",
       "0  LIBRO PRIMO DISPOSIZIONI GENERALI   TITOLO I DEGLI ORGANI GIUDIZIARI    \n",
       "1  LIBRO PRIMO DISPOSIZIONI GENERALI   TITOLO I DEGLI ORGANI GIUDIZIARI    \n",
       "2  LIBRO PRIMO DISPOSIZIONI GENERALI   TITOLO I DEGLI ORGANI GIUDIZIARI    \n",
       "3  LIBRO PRIMO DISPOSIZIONI GENERALI   TITOLO I DEGLI ORGANI GIUDIZIARI    \n",
       "4  LIBRO PRIMO DISPOSIZIONI GENERALI   TITOLO I DEGLI ORGANI GIUDIZIARI    \n",
       "\n",
       "                  capo                                            sezione  \\\n",
       "0  CAPO I Del giudice   Sezione I Della giurisdizione e della competen...   \n",
       "1  CAPO I Del giudice   Sezione I Della giurisdizione e della competen...   \n",
       "2  CAPO I Del giudice   Sezione I Della giurisdizione e della competen...   \n",
       "3  CAPO I Del giudice   Sezione I Della giurisdizione e della competen...   \n",
       "4  CAPO I Del giudice   Sezione I Della giurisdizione e della competen...   \n",
       "\n",
       "  numero_articolo                                    titolo_articolo  \\\n",
       "0               1              (Giurisdizione dei giudici ordinari).   \n",
       "1               2  ((ARTICOLO ABROGATO DALLA L. 31 MAGGIO 1995, N...   \n",
       "2               3  ((ARTICOLO ABROGATO DALLA L. 31 MAGGIO 1995, N...   \n",
       "3               4  ((ARTICOLO ABROGATO DALLA L. 31 MAGGIO 1995, N...   \n",
       "4               5  (Momento determinante della giurisdizione e de...   \n",
       "\n",
       "                                      testo_articolo  \n",
       "0  La giurisdizione civile, salvo speciali dispos...  \n",
       "1                                        PARSE ERROR  \n",
       "2                                        PARSE ERROR  \n",
       "3                                        PARSE ERROR  \n",
       "4  La giurisdizione e la competenza si determinan...  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# REad the RTF file and convert it to text\n",
    "\n",
    "file_name = 'Codice di Procedura Civile'\n",
    "\n",
    "rtf = read_from_file('./' + file_name + '.rtf')\n",
    "text = rtf_to_text(rtf)\n",
    "write_to_file(file_name + '.txt', text)\n",
    "\n",
    "# Split by CAPO\n",
    "libri = split_text(text, r'(LIBRO .+\\n.+\\n)')\n",
    "for i, libro in enumerate(libri):\n",
    "    write_to_file(f'libro_{i+1}.txt', libro)\n",
    "\n",
    "data = []\n",
    "\n",
    "contLibri = contTitoli = contCapitoli = contSezioni = contArrticoli = 0\n",
    "\n",
    "for l, libro in enumerate(libri):\n",
    "    # Skip the titles (keeping just the separated text)\n",
    "    if len(libro) < 100:\n",
    "        continue\n",
    "    contLibri+=1\n",
    "    \n",
    "    # Split by TITOLO\n",
    "    titoli = split_text(libro, r'(TITOLO [IVXL]+\\n.+\\n)')\n",
    "    \n",
    "    for t, titolo in enumerate(titoli):\n",
    "        # Skip the titles (keeping just the separated text)\n",
    "        if len(titolo) < 100:\n",
    "            continue\n",
    "        contTitoli+=1\n",
    "        \n",
    "        # Split by CAPO\n",
    "        capi = split_text(titolo, r'(^(.+)?CAPO [IVXL]+\\n.+\\n)')\n",
    "        \n",
    "        for c, capo in enumerate(capi):\n",
    "            \n",
    "            # Skip the titles (keeping just the separated text)\n",
    "            if len(capo) < 100:\n",
    "                continue\n",
    "            contCapitoli+=1\n",
    "            \n",
    "            # Split by SEZIONE\n",
    "            sezioni = split_text(capo, r'(Sezione [IVXL]+\\n.+\\n)')\n",
    "\n",
    "            for s, sezione in enumerate(sezioni):\n",
    "                \n",
    "                # Skip the titles (keeping just the separated text)\n",
    "                if len(sezione) < 100:\n",
    "                    continue\n",
    "                contSezioni+=1\n",
    "                \n",
    "                # Split by ARTICOLO\n",
    "                #articoli = split_text(text=sezione, pattern=r'(^(.+)?Art\\. \\d\\..+?\\n.+\\n(.+\\n)?)')\n",
    "                articoli = re.findall(r'Art\\. (\\d+)\\.(.*?)((?=Art\\.)|$)', sezione, re.DOTALL)\n",
    "    \n",
    "                for a, articolo in enumerate(articoli):\n",
    "                    contArrticoli+=1\n",
    "                    \n",
    "                    articolo_split = articolo[1].strip().split('\\n', 1)\n",
    "                    \n",
    "                    numero_articolo = articolo[0].strip()\n",
    "                    titolo_articolo = articolo_split[0].strip()\n",
    "                    testo_articolo = articolo_split[1].strip() if len(articolo_split) > 1 else ''      \n",
    "                    \n",
    "                    data.append({\n",
    "                        'libro': libri[l-1].replace('\\n', ' '),\n",
    "                        'titolo': titoli[t-1].replace('\\n', ' '),\n",
    "                        'capo': capi[c-1].replace('\\n', ' '),\n",
    "                        'sezione': sezioni[s-1].replace('\\n', ' '),\n",
    "                        'numero_articolo': numero_articolo if len(numero_articolo) > 0 else \"PARSE ERROR\",\n",
    "                        'titolo_articolo': titolo_articolo.replace('\\n', ' ') if len(titolo_articolo) > 1 else 'PARSE ERROR',\n",
    "                        'testo_articolo': testo_articolo.replace('\\n', ' ') if len(testo_articolo) > 1 else \"PARSE ERROR\",\n",
    "                    })\n",
    "                    \n",
    "\n",
    "print(f\"Libri: {contLibri}, Titoli: {contTitoli}, Capitoli: {contCapitoli}, Sezioni: {contSezioni}, Articoli: {contArrticoli}\")\n",
    "\n",
    "\n",
    "# Convert the list of dictionaries into a DataFrame\n",
    "df = pd.DataFrame(data)\n",
    "df.to_csv(file_name + '.csv', index=False)\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "BadRequestError",
     "evalue": "Error code: 400 - {'error': {'message': \"This model's maximum context length is 16384 tokens. However, your messages resulted in 18004 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m pdf_path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(os\u001b[38;5;241m.\u001b[39menviron[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPDF_PATH\u001b[39m\u001b[38;5;124m\"\u001b[39m], filename)\n\u001b[1;32m     10\u001b[0m text \u001b[38;5;241m=\u001b[39m extract_text_from_pdf(pdf_path)\n\u001b[0;32m---> 11\u001b[0m laws_json \u001b[38;5;241m=\u001b[39m \u001b[43mextract_laws\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFile: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilename\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExtracted JSON: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mlaws_json\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m, in \u001b[0;36mextract_laws\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mextract_laws\u001b[39m(text):\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtext\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:158\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    148\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    149\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    154\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    155\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    157\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 158\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    159\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    160\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    168\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:560\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    553\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    554\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    558\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    559\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 560\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:421\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n\u001b[1;32m    420\u001b[0m             run_managers[i]\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 421\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    422\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    423\u001b[0m     LLMResult(generations\u001b[38;5;241m=\u001b[39m[res\u001b[38;5;241m.\u001b[39mgenerations], llm_output\u001b[38;5;241m=\u001b[39mres\u001b[38;5;241m.\u001b[39mllm_output)  \u001b[38;5;66;03m# type: ignore[list-item]\u001b[39;00m\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results\n\u001b[1;32m    425\u001b[0m ]\n\u001b[1;32m    426\u001b[0m llm_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_combine_llm_outputs([res\u001b[38;5;241m.\u001b[39mllm_output \u001b[38;5;28;01mfor\u001b[39;00m res \u001b[38;5;129;01min\u001b[39;00m results])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:411\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    408\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    409\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    410\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 411\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    412\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    413\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    414\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    415\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    416\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m         )\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    419\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:632\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    630\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    631\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 632\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    633\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    634\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    635\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    636\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/langchain_openai/chat_models/base.py:522\u001b[0m, in \u001b[0;36mBaseChatOpenAI._generate\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    520\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    521\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 522\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_utils/_utils.py:277\u001b[0m, in \u001b[0;36mrequired_args.<locals>.inner.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    275\u001b[0m             msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing required argument: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquote(missing[\u001b[38;5;241m0\u001b[39m])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(msg)\n\u001b[0;32m--> 277\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/resources/chat/completions.py:590\u001b[0m, in \u001b[0;36mCompletions.create\u001b[0;34m(self, messages, model, frequency_penalty, function_call, functions, logit_bias, logprobs, max_tokens, n, presence_penalty, response_format, seed, stop, stream, stream_options, temperature, tool_choice, tools, top_logprobs, top_p, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    558\u001b[0m \u001b[38;5;129m@required_args\u001b[39m([\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m], [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodel\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstream\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m    559\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate\u001b[39m(\n\u001b[1;32m    560\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m     timeout: \u001b[38;5;28mfloat\u001b[39m \u001b[38;5;241m|\u001b[39m httpx\u001b[38;5;241m.\u001b[39mTimeout \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m|\u001b[39m NotGiven \u001b[38;5;241m=\u001b[39m NOT_GIVEN,\n\u001b[1;32m    589\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ChatCompletion \u001b[38;5;241m|\u001b[39m Stream[ChatCompletionChunk]:\n\u001b[0;32m--> 590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_post\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    591\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/chat/completions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    592\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaybe_transform\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    593\u001b[0m \u001b[43m            \u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    594\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    595\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmodel\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    596\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfrequency_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunction_call\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunction_call\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfunctions\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfunctions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_bias\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogit_bias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mlogprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmax_tokens\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mn\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpresence_penalty\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mresponse_format\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mresponse_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    605\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    606\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstop\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    607\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstream_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    609\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtemperature\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    610\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtool_choice\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtool_choice\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    611\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtools\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    612\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_logprobs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_logprobs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    613\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtop_p\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    614\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    615\u001b[0m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    616\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcompletion_create_params\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mCompletionCreateParams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    617\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    618\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmake_request_options\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    619\u001b[0m \u001b[43m            \u001b[49m\u001b[43mextra_headers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_headers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_query\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_query\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mextra_body\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextra_body\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtimeout\u001b[49m\n\u001b[1;32m    620\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    621\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mChatCompletion\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    623\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mStream\u001b[49m\u001b[43m[\u001b[49m\u001b[43mChatCompletionChunk\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    624\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1240\u001b[0m, in \u001b[0;36mSyncAPIClient.post\u001b[0;34m(self, path, cast_to, body, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1226\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpost\u001b[39m(\n\u001b[1;32m   1227\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1228\u001b[0m     path: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1235\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1236\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[1;32m   1237\u001b[0m     opts \u001b[38;5;241m=\u001b[39m FinalRequestOptions\u001b[38;5;241m.\u001b[39mconstruct(\n\u001b[1;32m   1238\u001b[0m         method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpost\u001b[39m\u001b[38;5;124m\"\u001b[39m, url\u001b[38;5;241m=\u001b[39mpath, json_data\u001b[38;5;241m=\u001b[39mbody, files\u001b[38;5;241m=\u001b[39mto_httpx_files(files), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions\n\u001b[1;32m   1239\u001b[0m     )\n\u001b[0;32m-> 1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(ResponseT, \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:921\u001b[0m, in \u001b[0;36mSyncAPIClient.request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m    912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrequest\u001b[39m(\n\u001b[1;32m    913\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    914\u001b[0m     cast_to: Type[ResponseT],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    919\u001b[0m     stream_cls: \u001b[38;5;28mtype\u001b[39m[_StreamT] \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    920\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ResponseT \u001b[38;5;241m|\u001b[39m _StreamT:\n\u001b[0;32m--> 921\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    922\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcast_to\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcast_to\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    923\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    924\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    925\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstream_cls\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstream_cls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    926\u001b[0m \u001b[43m        \u001b[49m\u001b[43mremaining_retries\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremaining_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/openai/_base_client.py:1020\u001b[0m, in \u001b[0;36mSyncAPIClient._request\u001b[0;34m(self, cast_to, options, remaining_retries, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1017\u001b[0m         err\u001b[38;5;241m.\u001b[39mresponse\u001b[38;5;241m.\u001b[39mread()\n\u001b[1;32m   1019\u001b[0m     log\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRe-raising status error\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 1020\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_status_error_from_response(err\u001b[38;5;241m.\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_response(\n\u001b[1;32m   1023\u001b[0m     cast_to\u001b[38;5;241m=\u001b[39mcast_to,\n\u001b[1;32m   1024\u001b[0m     options\u001b[38;5;241m=\u001b[39moptions,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1027\u001b[0m     stream_cls\u001b[38;5;241m=\u001b[39mstream_cls,\n\u001b[1;32m   1028\u001b[0m )\n",
      "\u001b[0;31mBadRequestError\u001b[0m: Error code: 400 - {'error': {'message': \"This model's maximum context length is 16384 tokens. However, your messages resulted in 18004 tokens. Please reduce the length of the messages.\", 'type': 'invalid_request_error', 'param': 'messages', 'code': 'context_length_exceeded'}}"
     ]
    }
   ],
   "source": [
    "# Extract laws from entire text\n",
    "\n",
    "def extract_laws(text):\n",
    "    return chain.invoke({\"text\": text })#\"La corte costituzionale ha dichiarato che la legge 122 e la legge 123 sono antinomie.\"})\n",
    "    \n",
    "for filename in os.listdir(os.environ[\"PDF_PATH\"]):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(os.environ[\"PDF_PATH\"], filename)\n",
    "        \n",
    "        text = extract_text_from_pdf(pdf_path)\n",
    "        laws_json = extract_laws(text)\n",
    "        \n",
    "        print(f\"File: {filename}\")\n",
    "        print(f\"Extracted JSON: {laws_json}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted JSON: {\n",
      "  \"first_law\": \"\",\n",
      "  \"second_law\": \"\",\n",
      "  \"are_antinomial\": 2\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Extract laws from summarized text\n",
    "\n",
    "map_prompt_template = \\\n",
    "\"\"\"Summarize the following text:\n",
    "\n",
    "{text}\n",
    "\n",
    "Summary:\"\"\"\n",
    "map_prompt = PromptTemplate(template=map_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Define the reduce step to summarize the combined summaries\n",
    "reduce_prompt_template = \\\n",
    "\"\"\"Summarize the following combined summaries:\n",
    "\n",
    "{text}\n",
    "\n",
    "Final Summary:\"\"\"\n",
    "reduce_prompt = PromptTemplate(template=reduce_prompt_template, input_variables=[\"text\"])\n",
    "\n",
    "# Function to split text into chunks\n",
    "def split_text(text):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\n",
    "        \".\\n\",\n",
    "    ],\n",
    "    chunk_size=7000, \n",
    "    chunk_overlap= 100)\n",
    "    \n",
    "    return text_splitter.create_documents([text])\n",
    "\n",
    "# Function to map (summarize each chunk)\n",
    "def map_summarize_chunks(chunks):\n",
    "    map_chain = map_prompt | llm# Chain(llm=llm, prompt_template=map_prompt)\n",
    "    chunk_summaries = [map_chain.invoke({\"text\": chunk.page_content}).content for chunk in chunks]\n",
    "    return chunk_summaries\n",
    "\n",
    "# Function to reduce (summarize the combined summaries)\n",
    "def reduce_summary(chunk_summaries):\n",
    "    combined_text = \" \".join(chunk_summaries)\n",
    "    reduce_chain = reduce_prompt | llm #Chain(llm=llm, prompt_template=reduce_prompt)\n",
    "    final_summary = reduce_chain.invoke({\"text\": combined_text}).content\n",
    "    return final_summary\n",
    "\n",
    "def process_pdf(filepath):\n",
    "    text = extract_text_from_pdf(filepath)\n",
    "    chunks = split_text(text)\n",
    "    for i, x in enumerate(chunks):\n",
    "        write_to_file(f'chunk{i}.txt', x.page_content)\n",
    "    chunk_summaries = map_summarize_chunks(chunks)\n",
    "    final_summary = reduce_summary(chunk_summaries)\n",
    "    return final_summary\n",
    "\n",
    "\n",
    "for filename in os.listdir(os.environ[\"PDF_PATH\"]):\n",
    "    if filename.endswith('.pdf'):\n",
    "        pdf_path = os.path.join(os.environ[\"PDF_PATH\"], filename)\n",
    "        final_summary = process_pdf(pdf_path)\n",
    "        #write_to_file('summary.txt', final_summary)\n",
    "        \n",
    "        laws_json = extract_laws(final_summary)\n",
    "        print(f\"Extracted JSON: {laws_json}\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles = [\n",
    "    \"Articolo 1: Testo del primo articolo di legge.\",\n",
    "    \"Articolo 2: Testo del secondo articolo di legge.\",\n",
    "]\n",
    "\n",
    "df = pd.DataFrame(articles, columns=['text'])\n",
    "\n",
    "def get_embeddings(texts, model_name):\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "    model = AutoModel.from_pretrained(model_name)\n",
    "    \n",
    "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True, max_length=512)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1)\n",
    "    return embeddings\n",
    "\n",
    "model_names = [\n",
    "    '../Models/SaulLM-7B_model',\n",
    "    '../Models/ChatLaw_model',\n",
    "    '../Models/LLama3-8B_model',\n",
    "    '../Models/MPT-7B_model',\n",
    "    '../Models/Falcon-7B_model'\n",
    "]\n",
    "\n",
    "embeddings_dict = {}\n",
    "for model_name in model_names:\n",
    "    embeddings = get_embeddings(df['text'].tolist(), model_name)\n",
    "    embeddings_dict[model_name] = embeddings\n",
    "\n",
    "# Save embeddings to files\n",
    "for model_name, embeddings in embeddings_dict.items():\n",
    "    np.save(f\"{model_name}_embeddings.npy\", embeddings.numpy())\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
