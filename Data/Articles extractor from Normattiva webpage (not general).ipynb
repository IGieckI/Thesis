{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting Codice Penale using BeautifulSoup (Failed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "(Elemento psicologico del reato) Il delitto:\n",
      "\n",
      "    Art. number                                               Text\n",
      "0             2  (Successione di leggi penali) Nessuno può esse...\n",
      "1             3  (Obbligatorietà della legge penale) La legge p...\n",
      "2             4  (Cittadino italiano. Territorio dello Stato) A...\n",
      "3             5  (Ignoranza della legge penale) Nessuno può inv...\n",
      "4             6  (Reati commessi nel territorio dello Stato) Ch...\n",
      "..          ...                                                ...\n",
      "578         725  (Commercio di scritti, disegni o altri oggetti...\n",
      "579         726  (Atti contrari alla pubblica decenza. Turpiloq...\n",
      "580         728  (Trattamento idoneo a sopprimere la coscienza ...\n",
      "581         733  (Danneggiamento al patrimonio archeologico, st...\n",
      "582         734  (Distruzione o deturpamento di bellezze natura...\n",
      "\n",
      "[583 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "def extract_articles_from_html(html_content):\n",
    "    # Define regex patterns to extract article numbers and texts\n",
    "    article_pattern = re.compile(r'<div style=\"text-align:center;\">\\s*Art\\.\\s*(\\d+)\\.\\s*<br>\\s*<br>\\s*\\((.*?)\\)\\s*</div>.*?<br>\\s*<br>\\s*(.*?)\\s*<br>', re.DOTALL)\n",
    "    \n",
    "    # Find all matches in the HTML content\n",
    "    matches = article_pattern.findall(html_content)\n",
    "    \n",
    "    # Initialize lists to store the article numbers and texts\n",
    "    article_numbers = []\n",
    "    article_texts = []\n",
    "    \n",
    "    for match in matches:\n",
    "        article_number = match[0]\n",
    "        article_title = match[1]\n",
    "        article_text = match[2].strip()\n",
    "        \n",
    "        # Combine title and text if you want to keep the title in the text\n",
    "        full_text = f'({article_title}) {article_text}'\n",
    "        \n",
    "        # Append the extracted information to the lists\n",
    "        article_numbers.append(article_number)\n",
    "        if article_number == '43':  \n",
    "            print(f\"\\n{full_text}\\n\")\n",
    "        article_texts.append(re.sub(r'<.+?>', '', full_text))\n",
    "    \n",
    "    \n",
    "    # Create a DataFrame from the extracted data\n",
    "    df = pd.DataFrame({\n",
    "        'Art. number': article_numbers,\n",
    "        'Text': article_texts\n",
    "    })\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "\n",
    "# Read the HTML content from the file\n",
    "file_path = os.getcwd() + \"/work/web pages to scrape/Normattiva - Codice Penale.html\"\n",
    "with open(file_path, 'r', encoding='utf-8') as file:\n",
    "    html_content = file.read()\n",
    "\n",
    "# Extract articles and create a dataframe\n",
    "articles_df = extract_articles_from_html(html_content)\n",
    "srticle_df = articles_df.to_csv('articles.csv', index=False)\n",
    "\n",
    "# Display the dataframe\n",
    "print(articles_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Codice Penale Amministrativo using Selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "# You need to download chromedriver and give the location path\n",
    "driver = webdriver.Chrome('/path/to/chromedriver')\n",
    "\n",
    "# URL of the webpage you want to access\n",
    "driver.get('https://www.example.com') \n",
    "\n",
    "# Find a button by its ID and click it\n",
    "button = driver.find_element(By.ID, 'button-id')\n",
    "button.click()\n",
    "\n",
    "# Find a text input by its name, clear it and type into it\n",
    "text_input = driver.find_element(By.NAME, 'input-name')\n",
    "text_input.clear()\n",
    "text_input.send_keys('Some text')\n",
    "\n",
    "# Submit a form by clicking the submit button\n",
    "submit_button = driver.find_element(By.XPATH, '//input[@type=\"submit\"]')\n",
    "submit_button.click()\n",
    "\n",
    "# don't forget to close the browser!\n",
    "driver.quit()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "thesis"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
