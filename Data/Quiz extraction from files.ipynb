{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import PyPDF2\n",
    "import pypandoc\n",
    "import pandas as pd\n",
    "import lxml.etree as ET\n",
    "\n",
    "from langchain_openai import AzureChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions and constants\n",
    "default_path = os.getcwd() + \"/work/\"\n",
    "DEFAULT_SAVE_DIR = default_path + \"documents/\"\n",
    "\n",
    "def write_to_file(filename, content):\n",
    "    with open(filename, 'w') as f:\n",
    "        f.write(content)\n",
    "\n",
    "def read_from_file(filename):\n",
    "    with open(filename, 'r') as f:\n",
    "        return f.read()\n",
    "\n",
    "# Different kind of text extraction from each type of file\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    text = \"\"\n",
    "    with open(pdf_path, 'rb') as file:\n",
    "        reader = PyPDF2.PdfReader(file)\n",
    "        for page_num in range(len(reader.pages)):\n",
    "            page = reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "    return text    \n",
    "\n",
    "def extract_text_from_xml(xml_path):\n",
    "    tree = ET.parse(xml_path)\n",
    "    root = tree.getroot()\n",
    "    return ET.tostring(root, encoding='unicode', method='text')\n",
    "\n",
    "def extract_text_from_rtf(rtf_path):\n",
    "    return pypandoc.convert_file(rtf_path, 'plain', format='rtf')\n",
    "\n",
    "\n",
    "def split_text(text, pattern):\n",
    "    parts = re.split(pattern, text, flags=re.MULTILINE)\n",
    "    \n",
    "    parts = [part for part in parts if part]\n",
    "    \n",
    "    if not re.match(pattern, parts[0]):\n",
    "        parts = parts[1:]\n",
    "    \n",
    "    return parts\n",
    "\n",
    "def split_text(text, max_chunk_size=7000, chunk_overlap=100):\n",
    "    text_splitter = RecursiveCharacterTextSplitter(separators=[\n",
    "        \"\\n\\n\",\n",
    "        \"\\n\",\n",
    "        \".\",\n",
    "    ],\n",
    "    chunk_size=max_chunk_size,\n",
    "    chunk_overlap=chunk_overlap)\n",
    "    \n",
    "    return text_splitter.split_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extraction of Codice Penale (from website of Procura Generale Trento)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Law number</th>\n",
       "      <th>Law title</th>\n",
       "      <th>Law text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Reati e pene: disposizione espressa di legge</td>\n",
       "      <td>1. Nessuno può essere punito per un fatto che ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Successione di leggi penali</td>\n",
       "      <td>1. Nessuno può essere punito per un fatto che,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Obbligatorietà della legge penale</td>\n",
       "      <td>1. La legge penale italiana obbliga tutti colo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Cittadino italiano</td>\n",
       "      <td>Territorio dello Stato.\\n1. Agli effetti della...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Ignoranza della legge penale</td>\n",
       "      <td>1. Nessuno può invocare a propria scusa l'igno...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Law number                                     Law title  \\\n",
       "0          1  Reati e pene: disposizione espressa di legge   \n",
       "1          2                   Successione di leggi penali   \n",
       "2          3             Obbligatorietà della legge penale   \n",
       "3          4                            Cittadino italiano   \n",
       "4          5                  Ignoranza della legge penale   \n",
       "\n",
       "                                            Law text  \n",
       "0  1. Nessuno può essere punito per un fatto che ...  \n",
       "1  1. Nessuno può essere punito per un fatto che,...  \n",
       "2  1. La legge penale italiana obbliga tutti colo...  \n",
       "3  Territorio dello Stato.\\n1. Agli effetti della...  \n",
       "4  1. Nessuno può invocare a propria scusa l'igno...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CODICE_PENALE_DIR = DEFAULT_SAVE_DIR + \"Codice penale.pdf\"\n",
    "\n",
    "text = extract_text_from_pdf(CODICE_PENALE_DIR)\n",
    "articles = re.findall(r'Articolo n\\.(\\d+)([\\s\\S]*?)(?=Articolo n\\.|\\Z)', text, re.M)\n",
    "\n",
    "data = []\n",
    "for article in articles:\n",
    "    law_number = article[0]\n",
    "    law_text = article[1].strip()\n",
    "    if '.' in law_text:\n",
    "        law_title, law_text = map(str.strip, law_text.split('.', 1))\n",
    "    else:\n",
    "        law_title = ''\n",
    "    data.append({'Law number': law_number, 'Law title': law_title, 'Law text': law_text})\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "notebookRunGroups": {
     "groupValue": "2"
    }
   },
   "source": [
    "### Check elements of the extracted Codice Penale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = \"e6e0bce8d2cf4675b61998097d298113\"\n",
    "# Other GPTs: 2024-02-01\n",
    "# GPT 4o: 2024-05-13\n",
    "os.environ[\"OPENAI_API_VERSION\"] = \"2024-02-01\"\n",
    "os.environ[\"AZURE_OPENAI_ENDPOINT\"] = \"https://mg-openai-adv.openai.azure.com/\"\n",
    "os.environ[\"PDF_PATH\"] = \"/home/utente/Scaricati/Legislative pdfs\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the model and the prompt template through AzureChatOpenAI\n",
    "\n",
    "# GPT3.5: mg-gpt-35-turbo-16k\n",
    "# GPT4: mg-gpt-4-0613\n",
    "# GPT4o: gpt-4o \n",
    "llm = AzureChatOpenAI(deployment_name=\"mg-gpt-35-turbo-16k\", temperature=0.7)\n",
    "\n",
    "prompt_template = \"\"\"\n",
    "    Tell me if there is something wrong with this text (if something is weird). JUST REPLY WITH TRUE IF SOMETHING IS WRONG, AND FALSE OTHERWISE.\n",
    "    {text}\n",
    "    \"\"\"\n",
    "\n",
    "messages = [\n",
    "    (\"system\", \"You are a helpful assistant specialized in analyzing legal texts.\"),\n",
    "    (\"user\", prompt_template)\n",
    "]\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(messages)\n",
    "\n",
    "chain = prompt | llm | StrOutputParser()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['True', 'True', 'TRUE', 'True', 'FALSE', 'True', 'FALSE', 'True', 'True', 'True', 'TRUE']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\ndf_results = pd.DataFrame(results_gpt, columns=[\\'Chunk\\', \\'Output\\', \\'Index\\'])\\n\\n# apply your parse_llm_JSONoutput function to df_results\\nparse_llm_JSONoutput(df_results, \"GPT4\")\\n'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_gpt = []\n",
    "\n",
    "for idx, row in df.iterrows():\n",
    "    if idx > 10:\n",
    "        break\n",
    "    law_text = row['Law text']\n",
    "    chunks = split_text(law_text, int(16000*0.8))\n",
    "\n",
    "    for chunk in chunks:\n",
    "        output = chain.invoke({\"text\": chunk })\n",
    "        if len(output) > 5:\n",
    "            output = \"True\"\n",
    "        results_gpt.append(output)\n",
    "print(results_gpt)\n",
    "\"\"\"\n",
    "df_results = pd.DataFrame(results_gpt, columns=['Chunk', 'Output', 'Index'])\n",
    "\n",
    "# apply your parse_llm_JSONoutput function to df_results\n",
    "parse_llm_JSONoutput(df_results, \"GPT4\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Law number                                                    1\n",
      "Law title          Reati e pene: disposizione espressa di legge\n",
      "Law text      1. Nessuno può essere punito per un fatto che ...\n",
      "Name: 0, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[0])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis11",
   "language": "python",
   "name": "thesis11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
